{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PAPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>PFPG</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>SOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.827586</td>\n",
       "      <td>65.344828</td>\n",
       "      <td>41.482759</td>\n",
       "      <td>18.206897</td>\n",
       "      <td>6.655172</td>\n",
       "      <td>5.862069</td>\n",
       "      <td>15.413793</td>\n",
       "      <td>11.758621</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.558824</td>\n",
       "      <td>67.529412</td>\n",
       "      <td>41.352941</td>\n",
       "      <td>19.911765</td>\n",
       "      <td>6.705882</td>\n",
       "      <td>5.705882</td>\n",
       "      <td>16.470588</td>\n",
       "      <td>13.176471</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.588235</td>\n",
       "      <td>68.147059</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>15.441176</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>4.147059</td>\n",
       "      <td>15.911765</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>15.843750</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>3.406250</td>\n",
       "      <td>15.843750</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.718750</td>\n",
       "      <td>67.031250</td>\n",
       "      <td>39.937500</td>\n",
       "      <td>14.593750</td>\n",
       "      <td>8.781250</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>18.562500</td>\n",
       "      <td>12.093750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>63.733333</td>\n",
       "      <td>38.766667</td>\n",
       "      <td>12.633333</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>75.470588</td>\n",
       "      <td>71.058824</td>\n",
       "      <td>34.882353</td>\n",
       "      <td>13.941176</td>\n",
       "      <td>5.764706</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>14.382353</td>\n",
       "      <td>12.294118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.903226</td>\n",
       "      <td>72.741935</td>\n",
       "      <td>41.548387</td>\n",
       "      <td>14.096774</td>\n",
       "      <td>6.322581</td>\n",
       "      <td>4.451613</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>13.903226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.233333</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>39.533333</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>14.933333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>76.911765</td>\n",
       "      <td>69.941176</td>\n",
       "      <td>38.352941</td>\n",
       "      <td>15.029412</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.735294</td>\n",
       "      <td>20.264706</td>\n",
       "      <td>14.205882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  TeamID  Wins  Losses        PPG       PAPG        RPG        APG  \\\n",
       "0   2022.0  1211.0  26.0     3.0  87.827586  65.344828  41.482759  18.206897   \n",
       "1   2022.0  1112.0  31.0     3.0  84.558824  67.529412  41.352941  19.911765   \n",
       "2   2022.0  1242.0  28.0     6.0  78.588235  68.147059  37.352941  15.441176   \n",
       "3   2022.0  1124.0  26.0     6.0  76.500000  63.625000  37.125000  15.843750   \n",
       "4   2022.0  1120.0  27.0     5.0  78.718750  67.031250  39.937500  14.593750   \n",
       "..     ...     ...   ...     ...        ...        ...        ...        ...   \n",
       "63  2022.0  1313.0  24.0     6.0  75.100000  63.733333  38.766667  12.633333   \n",
       "64  2022.0  1460.0  21.0    13.0  75.470588  71.058824  34.882353  13.941176   \n",
       "65  2022.0  1136.0  22.0     9.0  77.903226  72.741935  41.548387  14.096774   \n",
       "66  2022.0  1411.0  18.0    12.0  69.233333  65.500000  39.533333  10.833333   \n",
       "67  2022.0  1394.0  23.0    11.0  76.911765  69.941176  38.352941  15.029412   \n",
       "\n",
       "         SPG       BPG       PFPG       TOPG  SOS  \n",
       "0   6.655172  5.862069  15.413793  11.758621  0.0  \n",
       "1   6.705882  5.705882  16.470588  13.176471  0.0  \n",
       "2   6.411765  4.147059  15.911765  12.500000  0.0  \n",
       "3   8.812500  3.406250  15.843750  12.500000  0.0  \n",
       "4   8.781250  7.937500  18.562500  12.093750  0.0  \n",
       "..       ...       ...        ...        ...  ...  \n",
       "63  6.700000  3.666667  17.666667  14.000000  0.0  \n",
       "64  5.764706  2.941176  14.382353  12.294118  0.0  \n",
       "65  6.322581  4.451613  16.806452  13.903226  0.0  \n",
       "66  5.566667  5.000000  17.800000  14.933333  0.0  \n",
       "67  8.500000  1.735294  20.264706  14.205882  0.0  \n",
       "\n",
       "[68 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import matplotlib\n",
    "from matplotlib import pylab\n",
    "import pandas as pd\n",
    "\n",
    "cols = ['Season', 'TeamID', 'Wins', 'Losses', 'PPG', 'PAPG', 'RPG', 'APG', 'SPG', 'BPG', 'PFPG', 'TOPG', 'SOS']\n",
    "years = [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "temp_df = pd.read_csv(\"./MRegularSeasonDetailedResults.csv\",\n",
    "                    names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                    #dtype={'Season': 'str', 'DayNum': 'str', 'WTeamID': 'str', 'WScore': 'int', 'LTeamID': 'str', 'LScore': 'int', 'WLoc': 'str', 'NumOT': 'str', 'WFGM': 'int', 'WFGA': 'int', 'WFGM3': 'int', 'WFGA3': 'int', 'WFTM': 'int', 'WFTA': 'int', 'WOR': 'int', 'WDR': 'int', 'WAst': 'int', 'WTO': 'int', 'WStl': 'int', 'WBlk': 'int', 'WPF': 'int', 'LFGM': 'int', 'LFGA': 'int', 'LFGM3': 'int', 'LFGA3': 'int', 'LFTM': 'int', 'LFTA': 'int', 'LOR': 'int', 'LDR': 'int', 'LAst': 'int', 'LTO': 'int', 'LStl': 'int', 'LBlk': 'int', 'LPF': 'int'},\n",
    "                    encoding = \"ISO-8859-1\")\n",
    "\n",
    "tourney_temp_df = pd.read_csv(\"./MNCAATourneyDetailedResults.csv\",\n",
    "                        names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                        encoding = \"ISO-8859-1\")\n",
    "\n",
    "reg_season_df = temp_df.drop(labels=0, axis=0)\n",
    "tourney_df = tourney_temp_df.drop(labels=0, axis=0)\n",
    "\n",
    "team_avgs = pd.DataFrame(columns=cols)\n",
    "reg_season_df['Season'] = pd.to_numeric(reg_season_df['Season'])\n",
    "tourney_df['Season'] = pd.to_numeric(tourney_df['Season'])\n",
    "\n",
    "for year in years:\n",
    "    year_df = reg_season_df[reg_season_df['Season'] == year]\n",
    "    tourney_year_df = tourney_df[tourney_df['Season'] == year]\n",
    "    dict = {}\n",
    "    for index, row in tourney_year_df.iterrows():\n",
    "        #print(row['WTeamID'])\n",
    "        dict[int(row['WTeamID'])] = 1\n",
    "        dict[int(row['LTeamID'])] = 1\n",
    "    \n",
    "    for key in dict:\n",
    "        team_1211W = year_df[year_df['WTeamID'].apply(pd.to_numeric) == key]\n",
    "        team_1211L = year_df[year_df['LTeamID'].apply(pd.to_numeric) == key]\n",
    "        \n",
    "        #print(f\"key: \", key)\n",
    "        #print(f\"year: \", year)\n",
    "        #print(f\"w_df: \", team_1211W)\n",
    "        #print(f\"l_df: \", team_1211L)\n",
    "    \n",
    "        team_1211_Wdf = team_1211W[['Season', 'WTeamID', 'WScore', 'LScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].apply(pd.to_numeric)\n",
    "        team_1211_Ldf = team_1211L[['Season', 'LTeamID', 'LScore', 'WScore', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "        \n",
    "        w_sum = team_1211_Wdf.sum(axis=0, numeric_only=True)\n",
    "        \n",
    "        l_sum = {'Season': 0, 'LTeamID': 0, 'LScore': 0, 'WScore': 0, 'LFGM': 0, 'LFGA': 0, 'LFGM3': 0, 'LFGA3': 0, 'LFTM': 0, 'LFTA': 0, 'LOR': 0, 'LDR': 0, 'LAst': 0, 'LTO': 0, 'LStl': 0, 'LBlk': 0, 'LPF': 0}\n",
    "        if not team_1211L.empty:\n",
    "            l_sum = team_1211_Ldf.sum(axis=0, numeric_only=True)\n",
    "        \n",
    "        tot_games = (len(team_1211_Wdf.index) + len(team_1211_Ldf.index))\n",
    "\n",
    "        #print(f\"w_sum: \", w_sum)\n",
    "        #print(f\"l_sum: \", l_sum)\n",
    "        season_total = (w_sum['Season'] + l_sum['Season']) / tot_games\n",
    "\n",
    "        id_total = (w_sum['WTeamID'] + l_sum['LTeamID']) / tot_games\n",
    "        score_total = (w_sum['WScore'] + l_sum['LScore']) / tot_games\n",
    "        pa_total = (w_sum['LScore'] + l_sum['WScore']) / tot_games\n",
    "        rebs_total = (w_sum['WOR'] + l_sum['LOR'] + w_sum['WDR'] + l_sum['LDR']) / tot_games\n",
    "        ast_total = (w_sum['WAst'] + l_sum['LAst']) / tot_games\n",
    "        stl_total = (w_sum['WStl'] + l_sum['LStl']) / tot_games\n",
    "        blk_total = (w_sum['WBlk'] + l_sum['LBlk']) / tot_games\n",
    "        pf_total = (w_sum['WPF'] + l_sum['LPF']) / tot_games\n",
    "        to_total = (w_sum['WTO'] + l_sum['LTO']) / tot_games\n",
    "\n",
    "        sos_temp = 0\n",
    "        #d = {'Season': [season_total], 'TeamID': [id_total], 'Wins': [len(team_1211_Wdf.index)], 'Losses': [len(team_1211_Ldf.index)], 'PPG': [score_total], 'PAPG': [pa_total], 'RPG': [rebs_total], 'APG': [ast_total], 'SPG': [stl_total], 'BPG': [blk_total], 'PFPG': [pf_total], 'TOPG': [to_total]}\n",
    "        #temp_df = pd.DataFrame(data=d)\n",
    "        team_avgs.loc[len(team_avgs.index)] = [season_total, id_total, len(team_1211_Wdf.index), len(team_1211_Ldf.index), score_total, pa_total, rebs_total, ast_total, stl_total, blk_total, pf_total, to_total, sos_temp]\n",
    "        #print(rows)\n",
    "\n",
    "team_avgs\n",
    "\n",
    "#regular season 2022\n",
    "reg_2022_df = pd.read_csv(\"./2022RegularSeason.csv\",\n",
    "                    names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                    #dtype={'Season': 'str', 'DayNum': 'str', 'WTeamID': 'str', 'WScore': 'int', 'LTeamID': 'str', 'LScore': 'int', 'WLoc': 'str', 'NumOT': 'str', 'WFGM': 'int', 'WFGA': 'int', 'WFGM3': 'int', 'WFGA3': 'int', 'WFTM': 'int', 'WFTA': 'int', 'WOR': 'int', 'WDR': 'int', 'WAst': 'int', 'WTO': 'int', 'WStl': 'int', 'WBlk': 'int', 'WPF': 'int', 'LFGM': 'int', 'LFGA': 'int', 'LFGM3': 'int', 'LFGA3': 'int', 'LFTM': 'int', 'LFTA': 'int', 'LOR': 'int', 'LDR': 'int', 'LAst': 'int', 'LTO': 'int', 'LStl': 'int', 'LBlk': 'int', 'LPF': 'int'},\n",
    "                    encoding = \"ISO-8859-1\")\n",
    "reg_2022_df = reg_2022_df.drop(labels=0, axis=0)\n",
    "tourney_team_ids = [1211, 1112,1242,1124, 1120, 1246,1437, 1181, 1458, 1397,1345,1403,1417, 1228, 1344, 1116, 1163, 1222, 1388, 1234, 1104, 1261, 1400, 1161, 1425, 1293,1277, 1326, 1129, 1314, 1361,1371, 1166, 1395, 1266, 1272, 1362, 1274, 1260, 1172,1235, 1276,1461,1353,1231, 1439, 1323,1412,1350,1308,1151, 1355, 1436,1103, 1255,1463, 1159, 1286, 1174,1389,1240,1168,1209, 1313, 1460, 1136,1411, 1394]\n",
    "team_avgs_2022 = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in tourney_team_ids:\n",
    "    team_wins = reg_2022_df[reg_2022_df['WTeamID'] == str(key)]\n",
    "    team_losses = reg_2022_df[reg_2022_df['LTeamID'] == str(key)]\n",
    "    \n",
    "    team_win_df = team_wins[['Season', 'WTeamID', 'WScore', 'LScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].apply(pd.to_numeric)\n",
    "    team_loss_df = team_losses[['Season', 'LTeamID', 'LScore', 'WScore', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].apply(pd.to_numeric)\n",
    "\n",
    "    w_sum = team_win_df.sum(axis=0, numeric_only=True)\n",
    "\n",
    "    l_sum = {'Season': 0, 'LTeamID': 0, 'LScore': 0, 'LFGM': 0, 'LFGA': 0, 'LFGM3': 0, 'LFGA3': 0, 'LFTM': 0, 'LFTA': 0, 'LOR': 0, 'LDR': 0, 'LAst': 0, 'LTO': 0, 'LStl': 0, 'LBlk': 0, 'LPF': 0}\n",
    "    if not team_losses.empty:\n",
    "        l_sum = team_loss_df.sum(axis=0, numeric_only=True)\n",
    "\n",
    "    tot_games = (len(team_win_df.index) + len(team_loss_df.index))\n",
    "    season_total = (int(w_sum['Season']) + int(l_sum['Season'])) / tot_games\n",
    "    id_total = (w_sum['WTeamID'] + l_sum['LTeamID']) / tot_games\n",
    "    score_total = (w_sum['WScore'] + l_sum['LScore']) / tot_games\n",
    "    pa_total = (w_sum['LScore'] + l_sum['WScore']) / tot_games\n",
    "    rebs_total = (w_sum['WOR'] + l_sum['LOR'] + w_sum['WDR'] + l_sum['LDR']) / tot_games\n",
    "    ast_total = (w_sum['WAst'] + l_sum['LAst']) / tot_games\n",
    "    stl_total = (w_sum['WStl'] + l_sum['LStl']) / tot_games\n",
    "    blk_total = (w_sum['WBlk'] + l_sum['LBlk']) / tot_games\n",
    "    pf_total = (w_sum['WPF'] + l_sum['LPF']) / tot_games\n",
    "    to_total = (w_sum['WTO'] + l_sum['LTO']) / tot_games\n",
    "    sos_temp = 0\n",
    "    \n",
    "    team_avgs_2022.loc[len(team_avgs_2022.index)] = [season_total, id_total, len(team_win_df.index), len(team_loss_df.index), score_total, pa_total, rebs_total, ast_total, stl_total, blk_total, pf_total, to_total, sos_temp]\n",
    "team_avgs_2022\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season  TeamID  Wins  Losses        PPG       PAPG        RPG        APG  \\\n",
      "0    2006.0  1104.0  17.0    12.0  69.965517  67.137931  37.000000  12.206897   \n",
      "1    2006.0  1266.0  19.0    10.0  74.206897  69.655172  35.551724  15.275862   \n",
      "2    2006.0  1130.0  25.0     7.0  74.531250  66.875000  35.187500  17.812500   \n",
      "3    2006.0  1334.0  22.0     7.0  73.724138  63.586207  35.172414  15.655172   \n",
      "4    2006.0  1181.0  30.0     3.0  82.515152  68.969697  32.909091  15.363636   \n",
      "..      ...     ...   ...     ...        ...        ...        ...        ...   \n",
      "891  2019.0  1205.0  20.0    11.0  75.774194  73.419355  32.870968  13.612903   \n",
      "892  2019.0  1439.0  24.0     8.0  74.000000  62.093750  32.593750  15.343750   \n",
      "893  2019.0  1387.0  23.0    12.0  67.057143  63.742857  39.771429  12.971429   \n",
      "894  2019.0  1449.0  26.0     8.0  69.823529  64.382353  31.588235  11.676471   \n",
      "895  2019.0  1429.0  27.0     6.0  79.030303  67.090909  40.060606  17.090909   \n",
      "\n",
      "          SPG       BPG       PFPG       TOPG       SOS  \n",
      "0    6.344828  5.034483  13.827586  13.517241  0.578590  \n",
      "1    7.517241  3.068966  19.482759  14.793103  0.567223  \n",
      "2    5.937500  4.281250  16.500000  13.312500  0.532000  \n",
      "3    5.931034  2.103448  15.379310  12.551724  0.460328  \n",
      "4    9.545455  5.424242  17.484848  13.393939  0.586100  \n",
      "..        ...       ...        ...        ...       ...  \n",
      "891  6.225806  2.483871  16.193548  11.774194  0.446706  \n",
      "892  6.656250  2.312500  15.281250  11.375000  0.546237  \n",
      "893  7.085714  4.057143  17.485714  12.714286  0.508255  \n",
      "894  9.000000  5.735294  18.411765  13.352941  0.541900  \n",
      "895  6.121212  4.272727  18.636364  12.545455  0.510435  \n",
      "\n",
      "[896 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#SoS Calculation\n",
    "def SoS_calc(year = 0):\n",
    "    sos_dict = {}\n",
    "    \n",
    "    if year == 0:\n",
    "        for year in years:\n",
    "            working_df = reg_season_df[reg_season_df['Season'] == year]\n",
    "            working_df = working_df.filter([\"WTeamID\", \"LTeamID\"])\n",
    "            \n",
    "            for row in working_df.itertuples(index=False):\n",
    "                winner = int(row[0])\n",
    "                loser = int(row[1])\n",
    "                \n",
    "                if winner not in sos_dict:\n",
    "                    temp_sos = {\"opp_list\": [loser], \"wins\" : 1, \"losses\" : 0, \"win%\" : 0, \"ow%\" : 0, \"oow%\" : 0, \"sos\" : 0}\n",
    "                    sos_dict[winner] = temp_sos.copy()\n",
    "                    temp_sos.clear()\n",
    "                else:\n",
    "                    sos_dict[winner][\"opp_list\"].append(loser)\n",
    "                    sos_dict[winner][\"wins\"] += 1\n",
    "                    \n",
    "                if loser not in sos_dict:\n",
    "                    temp_sos = {\"opp_list\": [winner], \"wins\" : 0, \"losses\" : 1, \"win%\" : 0, \"ow%\" : 0, \"oow%\" : 0, \"sos\" : 0}\n",
    "                    sos_dict[loser] = temp_sos.copy()\n",
    "                    temp_sos.clear()                    \n",
    "                else:\n",
    "                    sos_dict[loser][\"opp_list\"].append(winner)\n",
    "                    sos_dict[loser][\"losses\"] += 1\n",
    "                    \n",
    "            for calc in [\"win%\", \"ow%\", \"oow%\", \"sos\"]:\n",
    "                for k, d in sos_dict.items():\n",
    "                    if calc == \"win%\":\n",
    "                        d[\"win%\"] = d[\"wins\"] / (d[\"wins\"] + d[\"losses\"])\n",
    "                        \n",
    "                    if calc == \"ow%\":\n",
    "                        sum_wp = 0\n",
    "                        num = 0\n",
    "                        for opp in d[\"opp_list\"]:\n",
    "                            sum_wp += sos_dict[opp][\"win%\"]\n",
    "                            num += 1\n",
    "                        d[\"ow%\"] = (sum_wp / num)\n",
    "                        \n",
    "                    if calc == \"oow%\":\n",
    "                        sum_ow = 0\n",
    "                        num = 0\n",
    "                        for opp in d[\"opp_list\"]:\n",
    "                            sum_ow += sos_dict[opp][\"ow%\"]\n",
    "                            num += 1\n",
    "                        d[\"oow%\"] = (sum_ow / num)\n",
    "                        d[\"sos\"] = (d[\"ow%\"] * 2 + d[\"oow%\"]) / 3\n",
    "                        \n",
    "                              \n",
    "            sos_year_df = team_avgs[team_avgs[\"Season\"] == year]\n",
    "            team_list = sos_year_df[\"TeamID\"].tolist()\n",
    "            for row in team_avgs[team_avgs[\"Season\"] == year].itertuples():\n",
    "                team_avgs.iat[row.Index, team_avgs.columns.get_loc(\"SOS\")] = sos_dict[row[2]][\"sos\"]\n",
    "                \n",
    "            \n",
    "            \n",
    "            sos_dict.clear()\n",
    "            \n",
    "    else: # TODO specify year\n",
    "        raise Exception(\"Year-by-year functionality not implemented yet!\")\n",
    "        \n",
    "    print(team_avgs)\n",
    "        \n",
    "SoS_calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2\n",
    "import random\n",
    "\n",
    "random.seed()\n",
    "\n",
    "# make a new empty dataframe to hold all of the data\n",
    "\n",
    "# note: \"Winner\" column will always be '1' because the winning team is always listed first;\n",
    "# it's included just for a classification metric for the machine learning\n",
    "train_cols = [\"Season\", \"Team1ID\", \"Team2ID\", \"Winner\", \"Team1W\", \"Team1L\", \"Team1PPG\", \"Team1PAPG\", \"Team1RPG\", \"Team1APG\", \"Team1SPG\", \\\n",
    "              \"Team1BPG\", \"Team1PFPG\", \"Team1TOPG\", \"Team1SOS\", \"Team2W\", \"Team2L\", \"Team2PPG\", \"Team2PAPG\", \"Team2RPG\", \"Team2APG\", \"Team2SPG\",\\\n",
    "              \"Team2BPG\", \"Team2PFPG\", \"Team2TOPG\", \"Team2SOS\"]\n",
    "\n",
    "\n",
    "\n",
    "# we just need three columns from our tourney_df\n",
    "trim_tourney_df = tourney_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "trim_tourney_df\n",
    "\n",
    "def trainingData():\n",
    "    train_DF_temp = pd.DataFrame(columns=train_cols)\n",
    "    for year in years:\n",
    "        avg_year_df = team_avgs[team_avgs['Season'] == year]\n",
    "        tourney_year_df = trim_tourney_df[trim_tourney_df['Season'] == year].apply(pd.to_numeric)\n",
    "\n",
    "        for index, row in tourney_year_df.iterrows():\n",
    "            # make a list that we can insert into the new dataframe\n",
    "            #first 4 values (last value is the \"Winner\" classification which is randomly chosen)\n",
    "\n",
    "            #randomly choose which slot the winning team goes into\n",
    "            winning_team = random.randint(1,2)\n",
    "            losing_team = 2 if winning_team == 1 else 1\n",
    "\n",
    "            #properly put winning team into correct row\n",
    "            team_id = [\"\", \"WTeamID\", \"LTeamID\"]\n",
    "            temp_list = [year, row[team_id[winning_team]], row[team_id[losing_team]], winning_team]\n",
    "            team1_row = avg_year_df[avg_year_df[\"TeamID\"] == temp_list[1]][cols[2:]].values.tolist()\n",
    "            team2_row = avg_year_df[avg_year_df[\"TeamID\"] == temp_list[2]][cols[2:]].values.tolist()\n",
    "            temp_list.extend(team1_row[0])\n",
    "            temp_list.extend(team2_row[0])\n",
    "\n",
    "            # add that list to our DF\n",
    "            temp_series = pd.Series(temp_list, index=train_cols)\n",
    "            train_DF_temp = train_DF_temp.append(temp_series, ignore_index=True)\n",
    "    return train_DF_temp\n",
    "\n",
    "train_DF = trainingData()\n",
    "\n",
    "train_data = train_DF[train_DF['Season'] >= 2010]\n",
    "train_labels = train_data['Winner']\n",
    "train_data = train_data.drop(columns=['Winner'])\n",
    "\n",
    "\n",
    "\n",
    "#train_data\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team2:  1209\n",
      "[[2022.0, 1209.0, 18.0, 10.0, 70.60714285714286, 64.75, 37.25, 13.535714285714286, 8.928571428571429, 4.464285714285714, 15.75, 11.857142857142858, 0.0]]\n",
      "team2:  1272\n",
      "[[2022.0, 1272.0, 21.0, 10.0, 75.41935483870968, 68.38709677419355, 38.74193548387097, 16.06451612903226, 8.709677419354838, 5.67741935483871, 18.70967741935484, 16.35483870967742, 0.0]]\n",
      "team2:  1308\n",
      "[[2022.0, 1308.0, 26.0, 6.0, 73.3125, 65.03125, 38.46875, 13.90625, 5.0625, 4.15625, 15.875, 14.0, 0.0]]\n",
      "team2:  1436\n",
      "[[2022.0, 1436.0, 28.0, 5.0, 74.93939393939394, 60.303030303030305, 35.09090909090909, 15.212121212121213, 5.212121212121212, 2.515151515151515, 13.787878787878787, 9.696969696969697, 0.0]]\n",
      "team2:  1323\n",
      "[[2022.0, 1323.0, 22.0, 10.0, 72.5, 66.84375, 34.0625, 14.15625, 5.09375, 1.875, 12.875, 10.34375, 0.0]]\n",
      "team2:  1286\n",
      "[[2022.0, 1286.0, 27.0, 7.0, 76.97058823529412, 68.47058823529412, 35.411764705882355, 13.176470588235293, 5.235294117647059, 3.735294117647059, 18.176470588235293, 12.794117647058824, 0.0]]\n",
      "team2:  1172\n",
      "[[2022.0, 1172.0, 27.0, 6.0, 75.57575757575758, 65.75757575757575, 34.21212121212121, 14.666666666666666, 4.666666666666667, 2.5757575757575757, 14.727272727272727, 9.848484848484848, 0.0]]\n",
      "team2:  1168\n",
      "[[2022.0, 1168.0, 21.0, 10.0, 70.25806451612904, 66.16129032258064, 33.54838709677419, 11.290322580645162, 7.258064516129032, 2.0, 16.06451612903226, 12.258064516129032, 0.0]]\n",
      "team2:  1313\n",
      "[[2022.0, 1313.0, 24.0, 6.0, 75.1, 63.733333333333334, 38.766666666666666, 12.633333333333333, 6.7, 3.6666666666666665, 17.666666666666668, 14.0, 0.0]]\n",
      "team2:  1266\n",
      "[[2022.0, 1266.0, 19.0, 12.0, 74.38709677419355, 70.87096774193549, 34.70967741935484, 16.0, 7.870967741935484, 5.096774193548387, 17.451612903225808, 12.451612903225806, 0.0]]\n",
      "team2:  1231\n",
      "[[2022.0, 1231.0, 20.0, 13.0, 71.48484848484848, 65.93939393939394, 36.27272727272727, 14.93939393939394, 5.7272727272727275, 4.96969696969697, 17.303030303030305, 11.878787878787879, 0.0]]\n",
      "team2:  1103\n",
      "[[2022.0, 1103.0, 24.0, 9.0, 71.18181818181819, 62.81818181818182, 34.96969696969697, 11.909090909090908, 5.848484848484849, 3.303030303030303, 15.818181818181818, 11.454545454545455, 0.0]]\n",
      "team2:  1439\n",
      "[[2022.0, 1439.0, 23.0, 12.0, 70.74285714285715, 62.285714285714285, 32.2, 14.4, 5.371428571428571, 3.2, 14.742857142857142, 10.8, 0.0]]\n",
      "team2:  1463\n",
      "[[2022.0, 1463.0, 19.0, 11.0, 72.33333333333333, 68.83333333333333, 35.96666666666667, 11.9, 6.233333333333333, 3.1666666666666665, 17.4, 12.866666666666667, 0.0]]\n",
      "team2:  1362\n",
      "[[2022.0, 1362.0, 24.0, 9.0, 77.06060606060606, 67.03030303030303, 37.96969696969697, 13.121212121212121, 7.696969696969697, 4.606060606060606, 17.90909090909091, 12.878787878787879, 0.0]]\n",
      "team2:  1389\n",
      "[[2022.0, 1389.0, 19.0, 11.0, 66.86666666666666, 61.766666666666666, 36.2, 12.2, 7.266666666666667, 4.933333333333334, 19.5, 13.866666666666667, 0.0]]\n",
      "team2:  1460\n",
      "[[2022.0, 1460.0, 21.0, 13.0, 75.47058823529412, 71.05882352941177, 34.88235294117647, 13.941176470588236, 5.764705882352941, 2.9411764705882355, 14.382352941176471, 12.294117647058824, 0.0]]\n",
      "team2:  1395\n",
      "[[2022.0, 1395.0, 20.0, 12.0, 68.09375, 65.0, 38.78125, 13.625, 6.28125, 4.21875, 15.3125, 14.53125, 0.0]]\n",
      "team2:  1412\n",
      "[[2022.0, 1412.0, 27.0, 7.0, 80.67647058823529, 66.29411764705883, 38.411764705882355, 12.970588235294118, 9.647058823529411, 4.264705882352941, 16.61764705882353, 11.470588235294118, 0.0]]\n",
      "team2:  1151\n",
      "[[2022.0, 1151.0, 27.0, 7.0, 74.79411764705883, 64.67647058823529, 35.911764705882355, 13.029411764705882, 7.176470588235294, 2.2058823529411766, 15.470588235294118, 11.0, 0.0]]\n",
      "team2:  1276\n",
      "[[2022.0, 1276.0, 17.0, 14.0, 73.03225806451613, 69.87096774193549, 35.54838709677419, 14.193548387096774, 4.774193548387097, 3.096774193548387, 15.64516129032258, 11.548387096774194, 0.0]]\n",
      "team2:  1255\n",
      "[[2022.0, 1255.0, 26.0, 6.0, 76.34375, 65.0625, 37.28125, 14.03125, 7.75, 2.4375, 15.5, 11.96875, 0.0]]\n",
      "team2:  1260\n",
      "[[2022.0, 1260.0, 25.0, 7.0, 73.8125, 61.71875, 33.90625, 15.0, 6.90625, 2.4375, 17.1875, 12.15625, 0.0]]\n",
      "team2:  1174\n",
      "[[2022.0, 1174.0, 22.0, 13.0, 71.65714285714286, 67.88571428571429, 32.285714285714285, 12.514285714285714, 6.571428571428571, 3.657142857142857, 15.371428571428572, 12.457142857142857, 0.0]]\n",
      "team2:  1411\n",
      "[[2022.0, 1411.0, 18.0, 12.0, 69.23333333333333, 65.5, 39.53333333333333, 10.833333333333334, 5.566666666666666, 5.0, 17.8, 14.933333333333334, 0.0]]\n",
      "team2:  1166\n",
      "[[2022.0, 1166.0, 22.0, 11.0, 69.03030303030303, 65.93939393939394, 38.27272727272727, 13.151515151515152, 5.363636363636363, 4.424242424242424, 13.454545454545455, 14.06060606060606, 0.0]]\n",
      "team2:  1350\n",
      "[[2022.0, 1350.0, 23.0, 12.0, 71.71428571428571, 68.28571428571429, 32.31428571428572, 14.657142857142857, 7.857142857142857, 2.2857142857142856, 13.885714285714286, 9.8, 0.0]]\n",
      "team2:  1355\n",
      "[[2022.0, 1355.0, 30.0, 4.0, 86.70588235294117, 73.38235294117646, 35.55882352941177, 15.176470588235293, 6.0588235294117645, 2.5, 15.441176470588236, 11.029411764705882, 0.0]]\n",
      "team2:  1235\n",
      "[[2022.0, 1235.0, 20.0, 12.0, 66.46875, 63.0, 32.0, 14.71875, 8.40625, 3.0625, 18.03125, 13.8125, 0.0]]\n",
      "team2:  1159\n",
      "[[2022.0, 1159.0, 23.0, 11.0, 76.05882352941177, 67.11764705882354, 36.1764705882353, 17.176470588235293, 6.235294117647059, 3.676470588235294, 14.529411764705882, 11.323529411764707, 0.0]]\n",
      "team2:  1274\n",
      "[[2022.0, 1274.0, 23.0, 10.0, 74.81818181818181, 71.03030303030303, 30.454545454545453, 14.030303030303031, 8.727272727272727, 2.9393939393939394, 14.93939393939394, 9.606060606060606, 0.0]]\n",
      "team2:  1240\n",
      "[[2022.0, 1240.0, 21.0, 10.0, 73.93548387096774, 66.80645161290323, 36.935483870967744, 14.483870967741936, 6.193548387096774, 2.935483870967742, 14.225806451612904, 13.258064516129032, 0.0]]\n",
      "team2:  1272\n",
      "[[2022.0, 1272.0, 21.0, 10.0, 75.41935483870968, 68.38709677419355, 38.74193548387097, 16.06451612903226, 8.709677419354838, 5.67741935483871, 18.70967741935484, 16.35483870967742, 0.0]]\n",
      "team2:  1116\n",
      "[[2022.0, 1116.0, 25.0, 8.0, 76.93939393939394, 68.54545454545455, 38.15151515151515, 14.090909090909092, 7.7272727272727275, 4.181818181818182, 16.87878787878788, 12.606060606060606, 0.0]]\n",
      "team2:  1403\n",
      "[[2022.0, 1403.0, 25.0, 9.0, 71.70588235294117, 60.3235294117647, 36.470588235294116, 13.558823529411764, 8.176470588235293, 3.4705882352941178, 16.176470588235293, 13.852941176470589, 0.0]]\n",
      "team2:  1181\n",
      "[[2022.0, 1181.0, 28.0, 6.0, 80.17647058823529, 67.1470588235294, 38.294117647058826, 16.91176470588235, 6.470588235294118, 5.529411764705882, 13.705882352941176, 10.235294117647058, 0.0]]\n",
      "team2:  1314\n",
      "[[2022.0, 1314.0, 24.0, 9.0, 77.51515151515152, 71.72727272727273, 39.75757575757576, 14.818181818181818, 5.424242424242424, 3.8484848484848486, 14.363636363636363, 11.666666666666666, 0.0]]\n",
      "team2:  1417\n",
      "[[2022.0, 1417.0, 25.0, 7.0, 76.375, 64.8125, 37.0625, 13.96875, 7.03125, 3.3125, 16.25, 9.15625, 0.0]]\n",
      "team2:  1345\n",
      "[[2022.0, 1345.0, 27.0, 7.0, 79.79411764705883, 68.76470588235294, 38.55882352941177, 16.61764705882353, 4.617647058823529, 3.5, 14.352941176470589, 11.676470588235293, 0.0]]\n",
      "team2:  1389\n",
      "[[2022.0, 1389.0, 19.0, 11.0, 66.86666666666666, 61.766666666666666, 36.2, 12.2, 7.266666666666667, 4.933333333333334, 19.5, 13.866666666666667, 0.0]]\n",
      "team2:  1395\n",
      "[[2022.0, 1395.0, 20.0, 12.0, 68.09375, 65.0, 38.78125, 13.625, 6.28125, 4.21875, 15.3125, 14.53125, 0.0]]\n",
      "team2:  1228\n",
      "[[2022.0, 1228.0, 22.0, 9.0, 75.7741935483871, 67.64516129032258, 38.61290322580645, 15.387096774193548, 5.161290322580645, 3.0, 16.419354838709676, 12.161290322580646, 0.0]]\n",
      "team2:  1397\n",
      "[[2022.0, 1397.0, 26.0, 7.0, 73.18181818181819, 62.75757575757576, 37.15151515151515, 16.12121212121212, 9.272727272727273, 4.393939393939394, 16.96969696969697, 12.424242424242424, 0.0]]\n",
      "team2:  1437\n",
      "[[2022.0, 1437.0, 26.0, 7.0, 72.63636363636364, 63.09090909090909, 34.93939393939394, 12.06060606060606, 6.242424242424242, 2.272727272727273, 15.242424242424242, 10.0, 0.0]]\n",
      "team2:  1166\n",
      "[[2022.0, 1166.0, 22.0, 11.0, 69.03030303030303, 65.93939393939394, 38.27272727272727, 13.151515151515152, 5.363636363636363, 4.424242424242424, 13.454545454545455, 14.06060606060606, 0.0]]\n",
      "team2:  1344\n",
      "[[2022.0, 1344.0, 25.0, 5.0, 71.8, 67.0, 37.46666666666667, 13.2, 5.033333333333333, 3.7666666666666666, 15.966666666666667, 11.666666666666666, 0.0]]\n",
      "team2:  1458\n",
      "[[2022.0, 1458.0, 24.0, 7.0, 70.70967741935483, 66.54838709677419, 34.935483870967744, 11.064516129032258, 5.290322580645161, 2.806451612903226, 16.967741935483872, 8.548387096774194, 0.0]]\n",
      "team2:  1120\n",
      "[[2022.0, 1120.0, 27.0, 5.0, 78.71875, 67.03125, 39.9375, 14.59375, 8.78125, 7.9375, 18.5625, 12.09375, 0.0]]\n",
      "team2:  1116\n",
      "[[2022.0, 1116.0, 25.0, 8.0, 76.93939393939394, 68.54545454545455, 38.15151515151515, 14.090909090909092, 7.7272727272727275, 4.181818181818182, 16.87878787878788, 12.606060606060606, 0.0]]\n",
      "team2:  1181\n",
      "[[2022.0, 1181.0, 28.0, 6.0, 80.17647058823529, 67.1470588235294, 38.294117647058826, 16.91176470588235, 6.470588235294118, 5.529411764705882, 13.705882352941176, 10.235294117647058, 0.0]]\n",
      "team2:  1417\n",
      "[[2022.0, 1417.0, 25.0, 7.0, 76.375, 64.8125, 37.0625, 13.96875, 7.03125, 3.3125, 16.25, 9.15625, 0.0]]\n",
      "team2:  1389\n",
      "[[2022.0, 1389.0, 19.0, 11.0, 66.86666666666666, 61.766666666666666, 36.2, 12.2, 7.266666666666667, 4.933333333333334, 19.5, 13.866666666666667, 0.0]]\n",
      "team2:  1222\n",
      "[[2022.0, 1222.0, 29.0, 5.0, 75.82352941176471, 58.88235294117647, 39.23529411764706, 16.735294117647058, 8.235294117647058, 5.205882352941177, 17.38235294117647, 11.323529411764707, 0.0]]\n",
      "team2:  1437\n",
      "[[2022.0, 1437.0, 26.0, 7.0, 72.63636363636364, 63.09090909090909, 34.93939393939394, 12.06060606060606, 6.242424242424242, 2.272727272727273, 15.242424242424242, 10.0, 0.0]]\n",
      "team2:  1344\n",
      "[[2022.0, 1344.0, 25.0, 5.0, 71.8, 67.0, 37.46666666666667, 13.2, 5.033333333333333, 3.7666666666666666, 15.966666666666667, 11.666666666666666, 0.0]]\n",
      "team2:  1274\n",
      "[[2022.0, 1274.0, 23.0, 10.0, 74.81818181818181, 71.03030303030303, 30.454545454545453, 14.030303030303031, 8.727272727272727, 2.9393939393939394, 14.93939393939394, 9.606060606060606, 0.0]]\n",
      "team2:  1181\n",
      "[[2022.0, 1181.0, 28.0, 6.0, 80.17647058823529, 67.1470588235294, 38.294117647058826, 16.91176470588235, 6.470588235294118, 5.529411764705882, 13.705882352941176, 10.235294117647058, 0.0]]\n",
      "team2:  1389\n",
      "[[2022.0, 1389.0, 19.0, 11.0, 66.86666666666666, 61.766666666666666, 36.2, 12.2, 7.266666666666667, 4.933333333333334, 19.5, 13.866666666666667, 0.0]]\n",
      "team2:  1437\n",
      "[[2022.0, 1437.0, 26.0, 7.0, 72.63636363636364, 63.09090909090909, 34.93939393939394, 12.06060606060606, 6.242424242424242, 2.272727272727273, 15.242424242424242, 10.0, 0.0]]\n",
      "team2:  1274\n",
      "[[2022.0, 1274.0, 23.0, 10.0, 74.81818181818181, 71.03030303030303, 30.454545454545453, 14.030303030303031, 8.727272727272727, 2.9393939393939394, 14.93939393939394, 9.606060606060606, 0.0]]\n",
      "team2:  1314\n",
      "[[2022.0, 1314.0, 24.0, 9.0, 77.51515151515152, 71.72727272727273, 39.75757575757576, 14.818181818181818, 5.424242424242424, 3.8484848484848486, 14.363636363636363, 11.666666666666666, 0.0]]\n",
      "team2:  1242\n",
      "[[2022.0, 1242.0, 28.0, 6.0, 78.58823529411765, 68.1470588235294, 37.35294117647059, 15.441176470588236, 6.411764705882353, 4.147058823529412, 15.911764705882353, 12.5, 0.0]]\n",
      "team2:  1242\n",
      "[[2022.0, 1242.0, 28.0, 6.0, 78.58823529411765, 68.1470588235294, 37.35294117647059, 15.441176470588236, 6.411764705882353, 4.147058823529412, 15.911764705882353, 12.5, 0.0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1ID</th>\n",
       "      <th>Team2ID</th>\n",
       "      <th>Team1W</th>\n",
       "      <th>Team1L</th>\n",
       "      <th>Team1PPG</th>\n",
       "      <th>Team1PAPG</th>\n",
       "      <th>Team1RPG</th>\n",
       "      <th>Team1APG</th>\n",
       "      <th>Team1SPG</th>\n",
       "      <th>...</th>\n",
       "      <th>Team2L</th>\n",
       "      <th>Team2PPG</th>\n",
       "      <th>Team2PAPG</th>\n",
       "      <th>Team2RPG</th>\n",
       "      <th>Team2APG</th>\n",
       "      <th>Team2SPG</th>\n",
       "      <th>Team2BPG</th>\n",
       "      <th>Team2PFPG</th>\n",
       "      <th>Team2TOPG</th>\n",
       "      <th>Team2SOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.827586</td>\n",
       "      <td>65.344828</td>\n",
       "      <td>41.482759</td>\n",
       "      <td>18.206897</td>\n",
       "      <td>6.655172</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.607143</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>13.535714</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>68.705882</td>\n",
       "      <td>60.764706</td>\n",
       "      <td>34.970588</td>\n",
       "      <td>11.529412</td>\n",
       "      <td>5.911765</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.419355</td>\n",
       "      <td>68.387097</td>\n",
       "      <td>38.741935</td>\n",
       "      <td>16.064516</td>\n",
       "      <td>8.709677</td>\n",
       "      <td>5.677419</td>\n",
       "      <td>18.709677</td>\n",
       "      <td>16.354839</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.187500</td>\n",
       "      <td>65.156250</td>\n",
       "      <td>40.875000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.968750</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.312500</td>\n",
       "      <td>65.031250</td>\n",
       "      <td>38.468750</td>\n",
       "      <td>13.906250</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76.939394</td>\n",
       "      <td>68.545455</td>\n",
       "      <td>38.151515</td>\n",
       "      <td>14.090909</td>\n",
       "      <td>7.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.939394</td>\n",
       "      <td>60.303030</td>\n",
       "      <td>35.090909</td>\n",
       "      <td>15.212121</td>\n",
       "      <td>5.212121</td>\n",
       "      <td>2.515152</td>\n",
       "      <td>13.787879</td>\n",
       "      <td>9.696970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79.968750</td>\n",
       "      <td>76.406250</td>\n",
       "      <td>39.968750</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>66.843750</td>\n",
       "      <td>34.062500</td>\n",
       "      <td>14.156250</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>10.343750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.823529</td>\n",
       "      <td>58.882353</td>\n",
       "      <td>39.235294</td>\n",
       "      <td>16.735294</td>\n",
       "      <td>8.235294</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.636364</td>\n",
       "      <td>63.090909</td>\n",
       "      <td>34.939394</td>\n",
       "      <td>12.060606</td>\n",
       "      <td>6.242424</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>15.242424</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.588235</td>\n",
       "      <td>68.147059</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>15.441176</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.818182</td>\n",
       "      <td>71.030303</td>\n",
       "      <td>30.454545</td>\n",
       "      <td>14.030303</td>\n",
       "      <td>8.727273</td>\n",
       "      <td>2.939394</td>\n",
       "      <td>14.939394</td>\n",
       "      <td>9.606061</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>67.147059</td>\n",
       "      <td>38.294118</td>\n",
       "      <td>16.911765</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.515152</td>\n",
       "      <td>71.727273</td>\n",
       "      <td>39.757576</td>\n",
       "      <td>14.818182</td>\n",
       "      <td>5.424242</td>\n",
       "      <td>3.848485</td>\n",
       "      <td>14.363636</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.636364</td>\n",
       "      <td>63.090909</td>\n",
       "      <td>34.939394</td>\n",
       "      <td>12.060606</td>\n",
       "      <td>6.242424</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.588235</td>\n",
       "      <td>68.147059</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>15.441176</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>4.147059</td>\n",
       "      <td>15.911765</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.515152</td>\n",
       "      <td>71.727273</td>\n",
       "      <td>39.757576</td>\n",
       "      <td>14.818182</td>\n",
       "      <td>5.424242</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.588235</td>\n",
       "      <td>68.147059</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>15.441176</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>4.147059</td>\n",
       "      <td>15.911765</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Team1ID  Team2ID  Team1W  Team1L   Team1PPG  Team1PAPG   Team1RPG  \\\n",
       "0   2022.0   1211.0   1209.0    26.0     3.0  87.827586  65.344828  41.482759   \n",
       "1   2022.0   1129.0   1272.0    27.0     7.0  68.705882  60.764706  34.970588   \n",
       "2   2022.0   1163.0   1308.0    23.0     9.0  75.187500  65.156250  40.875000   \n",
       "3   2022.0   1116.0   1436.0    25.0     8.0  76.939394  68.545455  38.151515   \n",
       "4   2022.0   1104.0   1323.0    19.0    13.0  79.968750  76.406250  39.968750   \n",
       "..     ...      ...      ...     ...     ...        ...        ...        ...   \n",
       "58  2022.0   1222.0   1437.0    29.0     5.0  75.823529  58.882353  39.235294   \n",
       "59  2022.0   1242.0   1274.0    28.0     6.0  78.588235  68.147059  37.352941   \n",
       "60  2022.0   1181.0   1314.0    28.0     6.0  80.176471  67.147059  38.294118   \n",
       "61  2022.0   1437.0   1242.0    26.0     7.0  72.636364  63.090909  34.939394   \n",
       "62  2022.0   1314.0   1242.0    24.0     9.0  77.515152  71.727273  39.757576   \n",
       "\n",
       "     Team1APG  Team1SPG  ...  Team2L   Team2PPG  Team2PAPG   Team2RPG  \\\n",
       "0   18.206897  6.655172  ...    10.0  70.607143  64.750000  37.250000   \n",
       "1   11.529412  5.911765  ...    10.0  75.419355  68.387097  38.741935   \n",
       "2   14.000000  5.968750  ...     6.0  73.312500  65.031250  38.468750   \n",
       "3   14.090909  7.727273  ...     5.0  74.939394  60.303030  35.090909   \n",
       "4   14.625000  7.000000  ...    10.0  72.500000  66.843750  34.062500   \n",
       "..        ...       ...  ...     ...        ...        ...        ...   \n",
       "58  16.735294  8.235294  ...     7.0  72.636364  63.090909  34.939394   \n",
       "59  15.441176  6.411765  ...    10.0  74.818182  71.030303  30.454545   \n",
       "60  16.911765  6.470588  ...     9.0  77.515152  71.727273  39.757576   \n",
       "61  12.060606  6.242424  ...     6.0  78.588235  68.147059  37.352941   \n",
       "62  14.818182  5.424242  ...     6.0  78.588235  68.147059  37.352941   \n",
       "\n",
       "     Team2APG  Team2SPG  Team2BPG  Team2PFPG  Team2TOPG  Team2SOS  \n",
       "0   13.535714  8.928571  4.464286  15.750000  11.857143       0.0  \n",
       "1   16.064516  8.709677  5.677419  18.709677  16.354839       0.0  \n",
       "2   13.906250  5.062500  4.156250  15.875000  14.000000       0.0  \n",
       "3   15.212121  5.212121  2.515152  13.787879   9.696970       0.0  \n",
       "4   14.156250  5.093750  1.875000  12.875000  10.343750       0.0  \n",
       "..        ...       ...       ...        ...        ...       ...  \n",
       "58  12.060606  6.242424  2.272727  15.242424  10.000000       0.0  \n",
       "59  14.030303  8.727273  2.939394  14.939394   9.606061       0.0  \n",
       "60  14.818182  5.424242  3.848485  14.363636  11.666667       0.0  \n",
       "61  15.441176  6.411765  4.147059  15.911765  12.500000       0.0  \n",
       "62  15.441176  6.411765  4.147059  15.911765  12.500000       0.0  \n",
       "\n",
       "[63 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "d = {'Team1ID': [1211,1129,1163,1116,1104,1403,1277,1181,1124,1314,1388,1417,1400,1345,1293,1246,1112,1371,1222,1228,1161,1397,1326,1437,1242,1361,1234,1344,1261,1458,1425,1120,1211,1308,1323,1277,1124,1388,1400,1293,1112,1222,1276,1326,1242,1350,1235,1274,1211,1403,1314,1345,1112,1276,1242,1235,1116,1314,1222,1242,1181,1437,1314], 'Team2ID': [1209,1272,1308,1436,1323,1286,1172,1168,1313,1266,1231,1103,1439,1463,1362,1389,1460,1395,1412,1151,1276,1255,1260,1174,1411,1166,1350,1355,1235,1159,1274,1240,1272,1116,1403,1181,1314,1417,1345,1389,1395,1228,1397,1437,1166,1344,1458,1120,1116,1181,1417,1389,1222,1437,1344,1274,1181,1389,1437,1274,1314,1242,1242]}\n",
    "test_cols = [\"Season\", \"Team1ID\", \"Team2ID\", \"Team1W\", \"Team1L\", \"Team1PPG\", \"Team1PAPG\", \"Team1RPG\", \"Team1APG\", \"Team1SPG\", \\\n",
    "              \"Team1BPG\", \"Team1PFPG\", \"Team1TOPG\", \"Team1Sos\", \"Team2W\", \"Team2L\", \"Team2PPG\", \"Team2PAPG\", \"Team2RPG\", \"Team2APG\", \"Team2SPG\",\\\n",
    "              \"Team2BPG\", \"Team2PFPG\", \"Team2TOPG\", \"Team2SOS\"]\n",
    "temp_tourn_df = pd.DataFrame(data=d)\n",
    "#winners = [2,1,1,2,1,2,2,1,2,1,1,1,1,2,1,1,1,1,1,2,1,2,1,1,2,1,1,1,1,2,2,1,2,1,2,1,1,2,2,2,2,2,2,2,1,1,1,2,1,2,1,1,2,2,1,2,2,2,1,2,2,1,2,1,2,2,2]\n",
    "tourney_2022_df = pd.DataFrame(columns=test_cols)\n",
    "\n",
    "for row in temp_tourn_df.iterrows():\n",
    "    #Doing the same as before but without winner column\n",
    "    temp_list = [2022, row[1]['Team1ID'], row[1]['Team2ID']]\n",
    "    print(f\"team2: \", row[1]['Team2ID'])\n",
    "    team1_row = team_avgs_2022[team_avgs_2022[\"TeamID\"] == row[1]['Team1ID']].values.tolist()\n",
    "    team2_row = team_avgs_2022[team_avgs_2022[\"TeamID\"] == row[1]['Team2ID']].values.tolist()\n",
    "    print(team2_row)\n",
    "    team1_row[0].pop(0)\n",
    "    team1_row[0].pop(0)\n",
    "    team2_row[0].pop(0)\n",
    "    team2_row[0].pop(0)\n",
    "\n",
    "    temp_list.extend(team1_row[0])\n",
    "    temp_list.extend(team2_row[0])\n",
    "        \n",
    "    # add that list to our DF\n",
    "    temp_series = pd.Series(temp_list, index=test_cols)\n",
    "    tourney_2022_df = tourney_2022_df.append(temp_series, ignore_index=True)\n",
    "\n",
    "tourney_2022_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    "predictions = model.predict(tourney_2022_df)\n",
    "\n",
    "\n",
    "# Correlation checking\n",
    "big_corr = []\n",
    "#for m in range(1):\n",
    "#    for n in range(10):\n",
    "#        corr = []\n",
    "#        for i in range(10):\n",
    "#            model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    " #           predictions1 = model.predict(test_data)\n",
    "  #          model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    "   #         predictions2 = model.predict(test_data)\n",
    "    #        sum1 = 0\n",
    "     #       for j in range(len(predictions1)):\n",
    "      #          sum1 = sum1 + 1 if predictions1[j] == predictions2[j] else sum1\n",
    "\n",
    "#            sum1 /= len(predictions1)\n",
    "#            corr.append(sum1)\n",
    " #           big_corr.append(sum1)\n",
    "  #          print(f\"Trial {m*100 + n*10 + i + 1}: {sum1}\")\n",
    "\n",
    "#        avg = sum(corr) / len(corr)\n",
    "#        print(avg)\n",
    "#        big_corr.append(avg)\n",
    "#        corr.clear()\n",
    "#    print(f\"Overall correlation average: {sum(big_corr)/len(big_corr)}\")\n",
    "#    big_corr.clear()\n",
    "\n",
    "\n",
    "#plt.hist(big_corr, density=True, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "63\n",
      "Vegas # of Games correct:  42\n",
      "Vegas # of Games missed:  21\n",
      "Vegas Accuracy:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "winners = [1,2,2,1,2,1,1,1,1,1,1,1,1,1,1,2,1,2,1,1,2,1,1,1,1,2,2,1,2,1,2,1,1,2,2,2,2,2,2,2,1,1,1,2,1,2,1,1,2,2,1,2,2,2,1,2,2,1,2,1,2,2,2]\n",
    "vegas_winners = [1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,1,2,2,1,1,1,2,2,1,2,2,2,1,1,2,1,1,2,1,2,2,1,1,1,1,2,2]\n",
    "\n",
    "vright = 0\n",
    "vwrong = 0\n",
    "print(len(vegas_winners))\n",
    "print(len(winners))\n",
    "for i in range(0,len(vegas_winners)):\n",
    "    if vegas_winners[i] == winners[i]:\n",
    "        vright += 1\n",
    "    else:\n",
    "        vwrong += 1\n",
    "\n",
    "#print(f\"# of Games correct: \",right)\n",
    "#print(f\"# of Games missed: \",wrong)\n",
    "#print(f\"Accuracy: \", (right) / (right + wrong))\n",
    "\n",
    "print(f\"Vegas # of Games correct: \",vright)\n",
    "print(f\"Vegas # of Games missed: \",vwrong)\n",
    "print(f\"Vegas Accuracy: \", (vright) / (vright + vwrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:  0.5555555555555556\n",
      "Decision Tree:  0.42857142857142855\n",
      "Random Forest:  0.6031746031746031\n",
      "MLP Acc:  0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def accuracy(preds):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    for i in range(0,len(preds)):\n",
    "        if preds[i] == winners[i]:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    return right / (right + wrong)\n",
    "\n",
    "bayes_model = MultinomialNB().fit(train_data, train_labels)\n",
    "bayes_preds = bayes_model.predict(tourney_2022_df)\n",
    "print(f\"Naive Bayes: \", accuracy(bayes_preds))\n",
    "\n",
    "tree_model = DecisionTreeClassifier().fit(train_data, train_labels)\n",
    "tree_preds = tree_model.predict(tourney_2022_df)\n",
    "print(f\"Decision Tree: \", accuracy(tree_preds))\n",
    "\n",
    "forest_model = RandomForestClassifier().fit(train_data, train_labels)\n",
    "forest_preds = forest_model.predict(tourney_2022_df)\n",
    "print(f\"Random Forest: \", accuracy(forest_preds))\n",
    "print(f\"MLP Acc: \", accuracy(predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Average score: 0.5303174603174605\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "def trainAndPredictXGB(classifier):\n",
    "    \n",
    "    train_DF = trainingData()\n",
    "\n",
    "    train_df_year = train_DF[train_DF['Season'] >= 2010]\n",
    "    \n",
    "    X = train_df_year.drop(\"Season\", axis=1)\n",
    "    X = X.drop([\"Winner\", \"Team1ID\", \"Team2ID\"], axis=1)\n",
    "    y = train_df_year[\"Winner\"]\n",
    "    y = y.astype(int)\n",
    "\n",
    "    test_X = tourney_2022_df.drop([\"Season\", \"Team1ID\", \"Team2ID\"], axis=1)\n",
    "    #print(test_X)\n",
    "\n",
    "    scaled_X = scaler.fit_transform(X.values)\n",
    "    scaled_test = scaler.fit_transform(test_X.values)\n",
    "    X_proc = pd.DataFrame(scaled_X, index = X.index, columns = X.columns)\n",
    "    test_proc = pd.DataFrame(scaled_test, index = test_X.index, columns = test_X.columns)\n",
    "\n",
    "    classifier.fit(X_proc, y)\n",
    "\n",
    "    preds = classifier.predict(test_proc)\n",
    "    return accuracy(preds)\n",
    "\n",
    "xgb_total = 0\n",
    "for i in range(100):\n",
    "    xgb_total += trainAndPredictXGB(xgb.XGBClassifier())\n",
    "print(f\"XGB Average score: {xgb_total / 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.5806349206349208\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "from sklearn import svm\n",
    "\n",
    "svm_total = 0\n",
    "for i in range(100):\n",
    "    svm_total += trainAndPredictXGB(svm.SVC())\n",
    "print(f\"Average score: {svm_total / 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "[1 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 2 2 2 1]\n",
      "Predicted: 1211  Real: 1211\n",
      "Predicted: 1129  Real: 1272\n",
      "Predicted: 1163  Real: 1308\n",
      "Predicted: 1436  Real: 1116\n",
      "Predicted: 1323  Real: 1323\n",
      "Predicted: 1403  Real: 1403\n",
      "Predicted: 1172  Real: 1277\n",
      "Predicted: 1181  Real: 1181\n",
      "Predicted: 1124  Real: 1124\n",
      "Predicted: 1266  Real: 1314\n",
      "Predicted: 1388  Real: 1388\n",
      "Predicted: 1417  Real: 1417\n",
      "Predicted: 1439  Real: 1400\n",
      "Predicted: 1345  Real: 1345\n",
      "Predicted: 1293  Real: 1293\n",
      "Predicted: 1246  Real: 1389\n",
      "Predicted: 1112  Real: 1112\n",
      "Predicted: 1371  Real: 1395\n",
      "Predicted: 1222  Real: 1222\n",
      "Predicted: 1151  Real: 1228\n",
      "Predicted: 1161  Real: 1276\n",
      "Predicted: 1397  Real: 1397\n",
      "Predicted: 1260  Real: 1326\n",
      "Predicted: 1437  Real: 1437\n",
      "Predicted: 1242  Real: 1242\n",
      "Predicted: 1361  Real: 1166\n",
      "Predicted: 1234  Real: 1350\n",
      "Predicted: 1355  Real: 1344\n",
      "Predicted: 1235  Real: 1235\n",
      "Predicted: 1159  Real: 1458\n",
      "Predicted: 1274  Real: 1274\n",
      "Predicted: 1120  Real: 1120\n",
      "Round 2\n",
      "[1 2 2 2 1 2 2 1 1 1 2 2 1 1 2 2]\n",
      "Predicted: 1211  Real: 1211\n",
      "Predicted: 1436  Real: 1116\n",
      "Predicted: 1403  Real: 1403\n",
      "Predicted: 1181  Real: 1181\n",
      "Predicted: 1124  Real: 1314\n",
      "Predicted: 1417  Real: 1417\n",
      "Predicted: 1345  Real: 1345\n",
      "Predicted: 1293  Real: 1389\n",
      "Predicted: 1112  Real: 1112\n",
      "Predicted: 1222  Real: 1222\n",
      "Predicted: 1397  Real: 1276\n",
      "Predicted: 1437  Real: 1437\n",
      "Predicted: 1242  Real: 1242\n",
      "Predicted: 1234  Real: 1344\n",
      "Predicted: 1159  Real: 1235\n",
      "Predicted: 1120  Real: 1274\n",
      "Round 3\n",
      "[1 2 1 2 1 1 1 2]\n",
      "Predicted: 1211  Real: 1116\n",
      "Predicted: 1181  Real: 1181\n",
      "Predicted: 1124  Real: 1314\n",
      "Predicted: 1293  Real: 1389\n",
      "Predicted: 1112  Real: 1222\n",
      "Predicted: 1397  Real: 1437\n",
      "Predicted: 1242  Real: 1242\n",
      "Predicted: 1120  Real: 1274\n",
      "Round 4\n",
      "[1 2 1 2]\n",
      "Predicted: 1211  Real: 1181\n",
      "Predicted: 1293  Real: 1314\n",
      "Predicted: 1112  Real: 1437\n",
      "Predicted: 1120  Real: 1242\n",
      "Round 5\n",
      "[2 1]\n",
      "Predicted: 1293  Real: 1314\n",
      "Predicted: 1112  Real: 1242\n",
      "Round 6\n",
      "[2]\n",
      "Predicted: 1112  Real: 1242\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "firstRound = {'Team1ID': [1211,1129,1163,1116,1104,1403,1277,1181,1124,1314,1388,1417,1400,1345,1293,1246,1112,1371,1222,1228,1161,1397,1326,1437,1242,1361,1234,1344,1261,1458,1425,1120], 'Team2ID': [1209,1272,1308,1436,1323,1286,1172,1168,1313,1266,1231,1103,1439,1463,1362,1389,1460,1395,1412,1151,1276,1255,1260,1174,1411,1166,1350,1355,1235,1159,1274,1240]}\n",
    "tournamentRounds = {'Round1': [1211,1272,1308,1116,1323,1403,1277,1181,1124,1314,1388,1417,1400,1345,1293,1389,1112,1395,1222,1228,1276,1397,1326,1437,1242,1166,1350,1344,1235,1458,1274,1120], \\\n",
    "                    'Round2': [1211,1116,1403,1181,1314,1417,1345,1389,1112,1222,1276,1437,1242,1344,1235,1274], \\\n",
    "                    'Round3': [1116,1181,1314,1389,1222,1437,1242,1274], \\\n",
    "                    'Round4': [1181,1314,1437,1242], 'Round5': [1314, 1242], 'Round6': [1242]}\n",
    "\n",
    "bracket_df = pd.DataFrame(data=firstRound)\n",
    "\n",
    "def tournament(round_bracket, round_num, bracket_score):\n",
    "    round_df = pd.DataFrame(columns=test_cols)\n",
    "    for row in round_bracket.iterrows():\n",
    "        temp_list = [2022, row[1]['Team1ID'], row[1]['Team2ID']]\n",
    "        team1_row = team_avgs_2022[team_avgs_2022[\"TeamID\"] == row[1]['Team1ID']].values.tolist()\n",
    "        team2_row = team_avgs_2022[team_avgs_2022[\"TeamID\"] == row[1]['Team2ID']].values.tolist()\n",
    "        team1_row[0].pop(0)\n",
    "        team1_row[0].pop(0)\n",
    "        team2_row[0].pop(0)\n",
    "        team2_row[0].pop(0)\n",
    "\n",
    "        temp_list.extend(team1_row[0])\n",
    "        temp_list.extend(team2_row[0])\n",
    "        # add that list to our DF\n",
    "        temp_series = pd.Series(temp_list, index=test_cols)\n",
    "        round_df = round_df.append(temp_series, ignore_index=True)\n",
    "        \n",
    "    #print(round_df)\n",
    "    round_X = round_df.drop([\"Season\", \"Team1ID\", \"Team2ID\"], axis=1)\n",
    "    scaled_test = scaler.fit_transform(round_X.values)\n",
    "    round_proc = pd.DataFrame(scaled_test, index = round_X.index, columns = round_X.columns)\n",
    "    \n",
    "    #print(round_proc)\n",
    "    preds = svm_cl.predict(round_proc)\n",
    "    print(f\"Round {round_num}\")\n",
    "    print(preds)\n",
    "    \n",
    "    #if(round_num == 1):\n",
    "        #return;\n",
    "    \n",
    "    round_dict = {'Team1ID': [], 'Team2ID': []}\n",
    "    winners_arr = []\n",
    "    for i in range(0, len(preds)):\n",
    "        if i % 2 == 0:\n",
    "            length = len(round_dict['Team1ID'])\n",
    "            val = 0\n",
    "            if preds[i] == 1:\n",
    "                val = round_bracket.iloc[i]['Team1ID']\n",
    "            else:\n",
    "                val = round_bracket.iloc[i]['Team2ID']\n",
    "                \n",
    "            round_dict['Team1ID'].append(val)\n",
    "            winners_arr.append(val)\n",
    "        else:\n",
    "            length = len(round_dict['Team2ID'])\n",
    "            val = 0\n",
    "            if preds[i] == 1:\n",
    "                val = round_bracket.iloc[i]['Team1ID']\n",
    "            else:\n",
    "                val = round_bracket.iloc[i]['Team2ID']\n",
    "                \n",
    "            round_dict['Team2ID'].append(val)\n",
    "            winners_arr.append(val)\n",
    "    for i in range(0, len(winners_arr)):\n",
    "        print(f\"Predicted: {winners_arr[i]}  Real: {tournamentRounds['Round' + str(round_num)][i]}\")\n",
    "        if winners_arr[i] == tournamentRounds['Round' + str(round_num)][i]:\n",
    "            bracket_score += 10 * (2^(round_num - 1))\n",
    "    if round_num < 6:\n",
    "        new_df = pd.DataFrame(data=round_dict)\n",
    "        tournament(new_df, round_num+1, bracket_score)\n",
    "    else:\n",
    "        print(bracket_score)\n",
    "        \n",
    "#tournament(ff_df, 1) \n",
    "tournament(bracket_df, 1, 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 500 coin flip brackets: 319.14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f0b95736760>,\n",
       "  <matplotlib.lines.Line2D at 0x7f0b95736ac0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f0b95751160>,\n",
       "  <matplotlib.lines.Line2D at 0x7f0b95751490>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f0b95736730>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f0b957517c0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f0b957366d0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAATeUlEQVR4nO3db2xVd57f8fcXQ+1JQrogSERsOqQNnTpxtmrXikYJapbQVdB2FfKEDEy3i4qVKFHk7lSVJknvg9k8sDSo1apZS1kJDXRYdcYJs90mqGq2k6aWkKWZRM7uagbGQ0JKk7hQcPijRVPsgvn2gQ/0Qgzc62u4vpz3S7LOOd97js/XEnx8/Dv/IjORJJXDomY3IEm6dQx9SSoRQ1+SSsTQl6QSMfQlqUQWN7uBG1mxYkWuWbOm2W1IUkv58MMPv8jMlVfXF3zor1mzhtHR0Wa3IUktJSI+na3u8I4klYihL0klYuhLUokY+pJUIoa+JJXIDUM/InZHxImIOFBV+zcR8cuI+FlE/KeI+LWqz16JiMMRcSginqyq/0ZE/Lz47I8iIub/x5FuvqGhIXp6emhra6Onp4ehoaFmtyTVrJYj/e8DG6+qvQv0ZOavAx8BrwBExIPAFuChYpvXI6Kt2OaPgeeAtcXX1d9TWvCGhoaoVCoMDg4yOTnJ4OAglUrF4FfLuGHoZ+Z+4NRVtR9n5oVi8adAVzG/CXgjM6cy8whwGHgkIlYBd2fmT3LmWc5/Ajw9Xz+EdKsMDAywa9cu1q9fz5IlS1i/fj27du1iYGCg2a1JNZmPMf3twDvFfCfwedVn40Wts5i/uj6riHguIkYjYnRiYmIeWpTmx9jYGOvWrbuitm7dOsbGxprUkVSfhkI/IirABeAHl0qzrJbXqc8qM3dmZm9m9q5c+aW7iKWm6e7uZmRk5IrayMgI3d3dTepIqs+cQz8itgG/A/zT/P+v3xoHVlet1gUcLepds9SlllKpVOjr62N4eJjz588zPDxMX18flUql2a1JNZnTs3ciYiPwEvB4Zv6fqo/2AT+MiD8E7mPmhO0HmTkdEWcj4uvA+8DvAYONtS7delu3bgWgv7+fsbExuru7GRgYuFyXFrq40TtyI2II+E1gBXAc+A4zV+u0AyeL1X6amc8X61eYGee/AHwrM98p6r3MXAn0FWbOAfRnDS/o7e3tTR+4Jkn1iYgPM7P3S/WF/mJ0Q1+S6net0PeOXEkqEUNfkkrE0JekEjH0JalEDH1JKhFDX5JKxNCXpBIx9CWpRAx9SSoRQ1+SSsTQl6QSMfQlqUQMfUkqEUNfkkrE0JekEjH0JalEDH1JKhFDX5JKxNCXpBIx9CWpRAx9SSoRQ1+SSsTQl6QSMfQlqUQMfUkqEUNfkkrkhqEfEbsj4kREHKiqLY+IdyPi42K6rOqzVyLicEQciognq+q/ERE/Lz77o4iI+f9xJEnXU8uR/veBjVfVXgbey8y1wHvFMhHxILAFeKjY5vWIaCu2+WPgOWBt8XX195Qk3WQ3DP3M3A+cuqq8CdhTzO8Bnq6qv5GZU5l5BDgMPBIRq4C7M/MnmZnAn1RtI0m6ReY6pn9vZh4DKKb3FPVO4POq9caLWmcxf3V9VhHxXESMRsToxMTEHFuUJF1tvk/kzjZOn9epzyozd2Zmb2b2rly5ct6ak6Sym2voHy+GbCimJ4r6OLC6ar0u4GhR75qlLrWcoaEhenp6aGtro6enh6GhoWa3JNVsrqG/D9hWzG8D3q6qb4mI9oi4n5kTth8UQ0BnI+LrxVU7v1e1jdQyhoaGqFQqDA4OMjk5yeDgIJVKxeBXy4iZ86rXWSFiCPhNYAVwHPgO8BawF/hbwGfA5sw8VaxfAbYDF4BvZeY7Rb2XmSuBvgK8A/TnjXYO9Pb25ujo6Bx+NGn+9fT0MDg4yPr16y/XhoeH6e/v58CBA9fZUrq1IuLDzOz9Ur2G3G0qQ18LSVtbG5OTkyxZsuRy7fz583R0dDA9Pd3EzqQrXSv0vSNXqkN3dzevvvrqFWP6r776Kt3d3c1uTaqJoS/VYf369ezYsYPt27dz9uxZtm/fzo4dO64Y7pEWMkNfqsPw8DAvvfQSu3fvZunSpezevZuXXnqJ4eHhZrcm1cQxfakOjumrVTimL82D7u5uRkZGrqiNjIw4pq+WYehLdahUKvT19TE8PMz58+cZHh6mr6+PSqXS7NakmixudgNSK9m6dSsA/f39jI2N0d3dzcDAwOW6tNA5pi9JtyHH9CVJhr4klYmhL9XJp2yqlXkiV6rDpads7tq1i3Xr1jEyMkJfXx+AJ3PVEjyRK9XBp2yqVfiUTWkeeEeuWoVX70jzwDty1eoMfakO3pGrVueJXKkO3pGrVueYviTdhhzTlyQZ+pJUJoa+JJWIoS9JJWLoS1KJGPqSVCKGvlQnn7KpVtZQ6EfEv4yIgxFxICKGIqIjIpZHxLsR8XExXVa1/isRcTgiDkXEk423L91al56yOTg4yOTkJIODg1QqFYNfLWPON2dFRCcwAjyYmeciYi/wX4AHgVOZ+d2IeBlYlpkvRcSDwBDwCHAf8N+Av5uZ131KlTdnaSHxKZtqFTfr5qzFwFciYjFwB3AU2ATsKT7fAzxdzG8C3sjMqcw8Ahxm5heA1DLGxsYYHx+/YnhnfHycsbGxZrcm1WTOz97JzP8VEf8W+Aw4B/w4M38cEfdm5rFinWMRcU+xSSfw06pvMV7UpJZx33338e1vf5sf/vCHl1+i8s1vfpP77ruv2a1JNZnzkX4xVr8JuJ+Z4Zo7I+J3r7fJLLVZx5Yi4rmIGI2I0YmJibm2KN0UEXHdZWkha2R45x8DRzJzIjPPA38GPAocj4hVAMX0RLH+OLC6avsuZoaDviQzd2Zmb2b2rly5soEWpfl19OhRduzYQX9/Px0dHfT397Njxw6OHp31n7K04DQS+p8BX4+IO2LmUGcDMAbsA7YV62wD3i7m9wFbIqI9Iu4H1gIfNLB/6Zbr7u6mq6uLAwcOMD09zYEDB+jq6vIlKmoZcw79zHwf+FPgL4CfF99rJ/Bd4Lci4mPgt4plMvMgsBf4BfDnwIs3unJHWmh8iYpanc/Tl+o0NDTEwMDA5ZeoVCoVX6KiBcfn6UuSfF2iVI9Ld+Tu2rXr8iWbfX19AB7tqyU4vCPVwTty1SquNbxj6Et1aGtrY3JykiVLllyunT9/no6ODqanvS5BC4dj+tI86O7uZmRk5IrayMiIl2yqZTimL9WhUqnwjW98gzvvvJNPP/2Ur371q/zqV7/itddea3ZrUk080pfmyMcvqBUZ+lIdBgYGePPNNzly5AjT09McOXKEN998k4GBgWa3JtXEE7lSHTyRq1bhiVxpHnR3d/PMM8/Q0dFBRNDR0cEzzzzjiVy1DENfqkNnZydvvfUW27dv58yZM2zfvp233nqLzk5fDaHW4PCOVIeOjg56e3sZHR1lamqK9vb2y8uTk5PNbk+6zOEdaR5MTU1x6NAhVq1axaJFi1i1ahWHDh1iamqq2a1JNTH0pTpNTU2xe/duJicn2b17t4GvluLNWVKdzp49y9atWzl+/Dj33nsvZ8+ebXZLUs080pfq1NHRwalTpwA4deoUHR0dTe5Iqp2hL9Vh8eLFtLW10dnZSUTQ2dlJW1sbixf7R7Nag/9SpTpcuHCBixcvcu7cOQDOnTvHuXPnuHjxYpM7k2rjkb5Uh/b2dh544AFOnDhBZnLixAkeeOAB2tvbm92aVBNDX6rD1NQUH330Ec8//zxnzpzh+eef56OPPvIKHrUMQ1+qQ0SwYcMG9u/fz/Lly9m/fz8bNmzwiZtqGYa+VIfM5JNPPmFwcJDJyUkGBwf55JNPWOh3tkuXeCJXqkN7ezuPPfYY/f39jI2N0d3dzWOPPcaxY8ea3ZpUE4/0pTo8++yzDA0NcfLkSQBOnjzJ0NAQzz77bJM7k2pj6Et1ePTRR7nrrrs4efIkFy9e5OTJk9x11108+uijzW5NqomhL9VhYGCAJ554gkWLZv7rLFq0iCeeeMI3Z6llNPRo5Yj4NeB7QA+QwHbgEPAmsAb4n8AzmXm6WP8VoA+YBv5FZv7XG+3DRytrIVm0aNGsJ20jwhu0tKDcrEcrvwb8eWb+PeDvA2PAy8B7mbkWeK9YJiIeBLYADwEbgdcjoq3B/Uu31KXAf+GFFzhz5gwvvPDCFXVpoZtz6EfE3cA/AnYBZOb/zcwzwCZgT7HaHuDpYn4T8EZmTmXmEeAw8Mhc9y81y9KlS9m8eTN33HEHmzdvZunSpc1uSapZI0f6fxuYAP59RPxlRHwvIu4E7s3MYwDF9J5i/U7g86rtx4val0TEcxExGhGjExMTDbQozb+NGzfS399PR0cH/f39bNy4sdktSTVr5Dr9xcA/BPoz8/2IeI1iKOcaZrtlcda/iTNzJ7ATZsb0G+hRmnc/+tGPaGtr4+LFi/zyl7/k4MGDzW5JqlkjR/rjwHhmvl8s/ykzvwSOR8QqgGJ6omr91VXbdwFHG9i/dMutXj3zT3h6evqK6aW6tNDNOfQz838Dn0fE14rSBuAXwD5gW1HbBrxdzO8DtkREe0TcD6wFPpjr/qVmGB8fr6suLTSNPoahH/hBRPwN4H8A/5yZXyR7I6IP+AzYDJCZByNiLzO/GC4AL2bmdIP7l26pzGTZsmWcPn36cu3qZWkha+iSzcz8q8zszcxfz8ynM/N0Zp7MzA2ZubaYnqpafyAz/05mfi0z32m8fenWO336NE899RQTExM89dRTBr5ainfkSnPw+OOPc8cdd/D44483uxWpLg3dkXsreEeuFpJLz81ftGgRFy9evDwFb9DSwnKz7siVSmfFihWXAz4zWbFiRZM7kmrn8/SlQq1vv/riiy8uz2fm5eVat/cvAjWTR/pSITNr+nr44Yev2O7hhx+ueVsDX83mkb5Up5/97GfAzJG9Ia5W45G+JJWIoS9JJWLoS1KJGPqSVCKGviSViKEvSSVi6EtSiRj6klQihr4klYihL0klYuhLUokY+pJUIoa+JJWIoS9JJWLoS1KJGPqSVCKGviSViKEvSSVi6EtSiRj6klQiDYd+RLRFxF9GxH8ulpdHxLsR8XExXVa17isRcTgiDkXEk43uW5JUn/k40v99YKxq+WXgvcxcC7xXLBMRDwJbgIeAjcDrEdE2D/uXJNWoodCPiC7gnwDfqypvAvYU83uAp6vqb2TmVGYeAQ4DjzSyf0lSfRo90v93wLeBi1W1ezPzGEAxvaeodwKfV603XtS+JCKei4jRiBidmJhosEVJ0iVzDv2I+B3gRGZ+WOsms9RythUzc2dm9mZm78qVK+faoiTpKosb2PYx4KmI+G2gA7g7Iv4DcDwiVmXmsYhYBZwo1h8HVldt3wUcbWD/kqQ6zflIPzNfycyuzFzDzAna/56ZvwvsA7YVq20D3i7m9wFbIqI9Iu4H1gIfzLlzSVLdGjnSv5bvAnsjog/4DNgMkJkHI2Iv8AvgAvBiZk7fhP1Lkq4hMmcdVl8went7c3R0tNltSF8SESz0/z8qr4j4MDN7r657R64klcjNGN6Rmm758uWcPn36pu8nYraL0ubPsmXLOHXq1E3dh8rF0Ndt6fTp07fF0MvN/qWi8nF4R5JKxNCXpBIx9CWpRAx9SSoRQ1+SSsTQl6QSMfQlqUQMfUkqEUNfkkrE0JekEvExDLot5Xfuhj/4m81uo2H5nbub3YJuM4a+bkvx6l/fNs/eyT9odhe6nTi8I0klYuhLUokY+pJUIoa+JJWIoS9JJWLoS1KJGPqSVCKGviSViDdn6bZ1O7xUfNmyZc1uQbcZQ1+3pVtxN25E3BZ3/apc5jy8ExGrI2I4IsYi4mBE/H5RXx4R70bEx8V0WdU2r0TE4Yg4FBFPzscPIEmqXSNj+heAf5WZ3cDXgRcj4kHgZeC9zFwLvFcsU3y2BXgI2Ai8HhFtjTQvSarPnEM/M49l5l8U82eBMaAT2ATsKVbbAzxdzG8C3sjMqcw8AhwGHpnr/iVJ9ZuXq3ciYg3wD4D3gXsz8xjM/GIA7ilW6wQ+r9psvKhJkm6RhkM/Iu4C/iPwrcz86+utOktt1rNgEfFcRIxGxOjExESjLUqSCg2FfkQsYSbwf5CZf1aUj0fEquLzVcCJoj4OrK7avAs4Otv3zcydmdmbmb0rV65spEVJUpVGrt4JYBcwlpl/WPXRPmBbMb8NeLuqviUi2iPifmAt8MFc9y9Jql8j1+k/Bvwz4OcR8VdF7V8D3wX2RkQf8BmwGSAzD0bEXuAXzFz582JmTjewf0lSneYc+pk5wuzj9AAbrrHNADAw131Kkhrjs3ckqUQMfUkqEUNfkkrE0JekEjH0JalEDH1JKhFDX5JKxNCXpBIx9CWpRAx9SSoRQ1+SSsTQl6QSMfQlqUQMfUkqEUNfkkrE0JekEjH0JalEDH1JKhFDX5JKpJEXo0u3lYhrvfJ5frfJzLq3keaLoS8VDGOVgcM7klQihr4klYihL0klYuhLUokY+pJUIoa+JJWIoS9JJWLoS1KJxEK/ISUiJoBPm92HNIsVwBfNbkK6hq9m5sqriws+9KWFKiJGM7O32X1I9XB4R5JKxNCXpBIx9KW529nsBqR6OaYvSSXikb4klYihL0klYuhLdYqI3RFxIiIONLsXqV6GvlS/7wMbm92ENBeGvlSnzNwPnGp2H9JcGPqSVCKGviSViKEvSSVi6EtSiRj6Up0iYgj4CfC1iBiPiL5m9yTVyscwSFKJeKQvSSVi6EtSiRj6klQihr4klYihL0klYuhLUokY+pJUIv8P37a7zEx7BSgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "actual_winners = ( #Teams are given an index starting at the top left and ending at the bottom right\n",
    "      [], #placeholder so each round can have the right index\n",
    "      [0,3,5,6,9,10,12,14,16,18,20,22,24,26,28,31,32,35,36,38,41,42,44,46,48,51,53,54,57,58,61,62], #rd 1\n",
    "      [0,6,10,14,18,22,26,31,32,36,41,46,48,54,57,61], #rd 2\n",
    "      [6,14,18,31,36,46,48,61], #rd 3 (E8)\n",
    "      [14,18,46,48], #rd 4 (F4)\n",
    "      [18,48], #rd 5 (final)\n",
    "      [48]) #rd 6 (winner)\n",
    "\n",
    "# coin-flip bracket\n",
    "def pick_round(teams):\n",
    "    loser_list = []\n",
    "    \n",
    "    for i in range(0, len(teams) - 1, 2):\n",
    "        loser_list.append(i + randint(0,1)) # get a list of random losers\n",
    "        \n",
    "    loser_list.reverse() #reverse the list so it's in reverse numerical order (so we can remove by index)\n",
    "    for loser in loser_list:\n",
    "        teams.pop(loser)\n",
    "        \n",
    "    return teams\n",
    "\n",
    "def coin_flip(actual_winners):\n",
    "    sim_tourney = list(range(0, 64))\n",
    "    predicted_winners = [[]]\n",
    "    score = 0\n",
    "    \n",
    "    for rd in range(1,7):\n",
    "        sim_tourney = pick_round(sim_tourney)\n",
    "        predicted_winners.append(sim_tourney[:])\n",
    "    \n",
    "    for rd in range(1,7):\n",
    "        for game in range(0, len(predicted_winners[rd])):\n",
    "            score = (score + 10 * (2 ** (rd - 1))) if predicted_winners[rd][game] == actual_winners[rd][game] else score\n",
    "        \n",
    "    return score\n",
    "\n",
    "coin_flips = []\n",
    "\n",
    "num_coin_flips = 500\n",
    "for i in range(0, num_coin_flips):\n",
    "    coin_flips.append(coin_flip(actual_winners))\n",
    "    \n",
    "print(f\"Average of {num_coin_flips} coin flip brackets: {sum(coin_flips) / len(coin_flips)}\")\n",
    "    \n",
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.boxplot(coin_flips)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
