{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (0,1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>PFPG</th>\n",
       "      <th>TOPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.843750</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>7.656250</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>16.937500</td>\n",
       "      <td>15.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66.806452</td>\n",
       "      <td>39.225806</td>\n",
       "      <td>12.354839</td>\n",
       "      <td>7.645161</td>\n",
       "      <td>3.064516</td>\n",
       "      <td>20.870968</td>\n",
       "      <td>16.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.965517</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>12.206897</td>\n",
       "      <td>6.344828</td>\n",
       "      <td>5.034483</td>\n",
       "      <td>13.827586</td>\n",
       "      <td>13.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.206897</td>\n",
       "      <td>35.551724</td>\n",
       "      <td>15.275862</td>\n",
       "      <td>7.517241</td>\n",
       "      <td>3.068966</td>\n",
       "      <td>19.482759</td>\n",
       "      <td>14.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.531250</td>\n",
       "      <td>35.187500</td>\n",
       "      <td>17.812500</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>4.281250</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>13.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>75.774194</td>\n",
       "      <td>32.870968</td>\n",
       "      <td>13.612903</td>\n",
       "      <td>6.225806</td>\n",
       "      <td>2.483871</td>\n",
       "      <td>16.193548</td>\n",
       "      <td>11.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>32.593750</td>\n",
       "      <td>15.343750</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>15.281250</td>\n",
       "      <td>11.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>67.057143</td>\n",
       "      <td>39.771429</td>\n",
       "      <td>12.971429</td>\n",
       "      <td>7.085714</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>17.485714</td>\n",
       "      <td>12.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.823529</td>\n",
       "      <td>31.588235</td>\n",
       "      <td>11.676471</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.735294</td>\n",
       "      <td>18.411765</td>\n",
       "      <td>13.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.030303</td>\n",
       "      <td>40.060606</td>\n",
       "      <td>17.090909</td>\n",
       "      <td>6.121212</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>18.636364</td>\n",
       "      <td>12.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  TeamID  Wins  Losses        PPG        RPG        APG       SPG  \\\n",
       "0    2006.0  1284.0  18.0    14.0  64.843750  32.656250  14.656250  7.656250   \n",
       "1    2006.0  1214.0  16.0    15.0  66.806452  39.225806  12.354839  7.645161   \n",
       "2    2006.0  1104.0  17.0    12.0  69.965517  37.000000  12.206897  6.344828   \n",
       "3    2006.0  1266.0  19.0    10.0  74.206897  35.551724  15.275862  7.517241   \n",
       "4    2006.0  1130.0  25.0     7.0  74.531250  35.187500  17.812500  5.937500   \n",
       "..      ...     ...   ...     ...        ...        ...        ...       ...   \n",
       "932  2019.0  1205.0  20.0    11.0  75.774194  32.870968  13.612903  6.225806   \n",
       "933  2019.0  1439.0  24.0     8.0  74.000000  32.593750  15.343750  6.656250   \n",
       "934  2019.0  1387.0  23.0    12.0  67.057143  39.771429  12.971429  7.085714   \n",
       "935  2019.0  1449.0  26.0     8.0  69.823529  31.588235  11.676471  9.000000   \n",
       "936  2019.0  1429.0  27.0     6.0  79.030303  40.060606  17.090909  6.121212   \n",
       "\n",
       "          BPG       PFPG       TOPG  \n",
       "0    3.437500  16.937500  15.093750  \n",
       "1    3.064516  20.870968  16.225806  \n",
       "2    5.034483  13.827586  13.517241  \n",
       "3    3.068966  19.482759  14.793103  \n",
       "4    4.281250  16.500000  13.312500  \n",
       "..        ...        ...        ...  \n",
       "932  2.483871  16.193548  11.774194  \n",
       "933  2.312500  15.281250  11.375000  \n",
       "934  4.057143  17.485714  12.714286  \n",
       "935  5.735294  18.411765  13.352941  \n",
       "936  4.272727  18.636364  12.545455  \n",
       "\n",
       "[937 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pylab\n",
    "import pandas as pd\n",
    "\n",
    "cols = ['Season', 'TeamID', 'Wins', 'Losses', 'PPG', 'RPG', 'APG', 'SPG', 'BPG', 'PFPG', 'TOPG']\n",
    "years = [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "temp_df = pd.read_csv(\"./MRegularSeasonDetailedResults.csv\",\n",
    "                    names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                    #dtype={'Season': 'str', 'DayNum': 'str', 'WTeamID': 'str', 'WScore': 'int', 'LTeamID': 'str', 'LScore': 'int', 'WLoc': 'str', 'NumOT': 'str', 'WFGM': 'int', 'WFGA': 'int', 'WFGM3': 'int', 'WFGA3': 'int', 'WFTM': 'int', 'WFTA': 'int', 'WOR': 'int', 'WDR': 'int', 'WAst': 'int', 'WTO': 'int', 'WStl': 'int', 'WBlk': 'int', 'WPF': 'int', 'LFGM': 'int', 'LFGA': 'int', 'LFGM3': 'int', 'LFGA3': 'int', 'LFTM': 'int', 'LFTA': 'int', 'LOR': 'int', 'LDR': 'int', 'LAst': 'int', 'LTO': 'int', 'LStl': 'int', 'LBlk': 'int', 'LPF': 'int'},\n",
    "                    encoding = \"ISO-8859-1\")\n",
    "\n",
    "tourney_temp_df = pd.read_csv(\"./MNCAATourneyDetailedResults.csv\",\n",
    "                        names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                        encoding = \"ISO-8859-1\")\n",
    "\n",
    "reg_season_df = temp_df.drop(labels=0, axis=0)\n",
    "tourney_df = tourney_temp_df.drop(labels=0, axis=0)\n",
    "\n",
    "team_avgs = pd.DataFrame(columns=cols)\n",
    "reg_season_df['Season'] = pd.to_numeric(reg_season_df['Season'])\n",
    "tourney_df['Season'] = pd.to_numeric(tourney_df['Season'])\n",
    "\n",
    "for year in years:\n",
    "    year_df = reg_season_df[reg_season_df['Season'] == year]\n",
    "    tourney_year_df = tourney_df[tourney_df['Season'] == year]\n",
    "    dict = {}\n",
    "    for index, row in tourney_year_df.iterrows():\n",
    "        #print(row['WTeamID'])\n",
    "        dict[int(row['WTeamID'])] = 1\n",
    "        dict[int(row['LTeamID'])] = 1\n",
    "    \n",
    "    for key in dict:\n",
    "        team_1211W = year_df[year_df['WTeamID'].apply(pd.to_numeric) == key]\n",
    "        team_1211L = year_df[year_df['LTeamID'].apply(pd.to_numeric) == key]\n",
    "        \n",
    "        #print(f\"key: \", key)\n",
    "        #print(f\"year: \", year)\n",
    "        #print(f\"w_df: \", team_1211W)\n",
    "        #print(f\"l_df: \", team_1211L)\n",
    "    \n",
    "        team_1211_Wdf = team_1211W[['Season', 'WTeamID', 'WScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].apply(pd.to_numeric)\n",
    "        team_1211_Ldf = team_1211L[['Season', 'LTeamID', 'LScore', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "        \n",
    "        w_sum = team_1211_Wdf.sum(axis=0, numeric_only=True)\n",
    "        \n",
    "        l_sum = {'Season': 0, 'LTeamID': 0, 'LScore': 0, 'LFGM': 0, 'LFGA': 0, 'LFGM3': 0, 'LFGA3': 0, 'LFTM': 0, 'LFTA': 0, 'LOR': 0, 'LDR': 0, 'LAst': 0, 'LTO': 0, 'LStl': 0, 'LBlk': 0, 'LPF': 0}\n",
    "        if not team_1211L.empty:\n",
    "            l_sum = team_1211_Ldf.sum(axis=0, numeric_only=True)\n",
    "        \n",
    "        tot_games = (len(team_1211_Wdf.index) + len(team_1211_Ldf.index))\n",
    "\n",
    "        #print(f\"w_sum: \", w_sum)\n",
    "        #print(f\"l_sum: \", l_sum)\n",
    "        season_total = (w_sum['Season'] + l_sum['Season']) / tot_games\n",
    "\n",
    "        id_total = (w_sum['WTeamID'] + l_sum['LTeamID']) / tot_games\n",
    "        score_total = (w_sum['WScore'] + l_sum['LScore']) / tot_games\n",
    "        rebs_total = (w_sum['WOR'] + l_sum['LOR'] + w_sum['WDR'] + l_sum['LDR']) / tot_games\n",
    "        ast_total = (w_sum['WAst'] + l_sum['LAst']) / tot_games\n",
    "        stl_total = (w_sum['WStl'] + l_sum['LStl']) / tot_games\n",
    "        blk_total = (w_sum['WBlk'] + l_sum['LBlk']) / tot_games\n",
    "        pf_total = (w_sum['WPF'] + l_sum['LPF']) / tot_games\n",
    "        to_total = (w_sum['WTO'] + l_sum['LTO']) / tot_games\n",
    "\n",
    "        d = {'Season': [season_total], 'TeamID': [id_total], 'Wins': [len(team_1211_Wdf.index)], 'Losses': [len(team_1211_Ldf.index)], 'PPG': [score_total], 'RPG': [rebs_total], 'APG': [ast_total], 'SPG': [stl_total], 'BPG': [blk_total], 'PFPG': [pf_total], 'TOPG': [to_total]}\n",
    "        #temp_df = pd.DataFrame(data=d)\n",
    "        team_avgs.loc[len(team_avgs.index)] = [season_total, id_total, len(team_1211_Wdf.index), len(team_1211_Ldf.index), score_total, rebs_total, ast_total, stl_total, blk_total, pf_total, to_total]\n",
    "        #print(rows)\n",
    "\n",
    "team_avgs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1ID</th>\n",
       "      <th>Team2ID</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Team1W</th>\n",
       "      <th>Team1L</th>\n",
       "      <th>Team1PPG</th>\n",
       "      <th>Team1RPG</th>\n",
       "      <th>Team1APG</th>\n",
       "      <th>Team1SPG</th>\n",
       "      <th>...</th>\n",
       "      <th>Team1TOPG</th>\n",
       "      <th>Team2W</th>\n",
       "      <th>Team2L</th>\n",
       "      <th>Team2PPG</th>\n",
       "      <th>Team2RPG</th>\n",
       "      <th>Team2APG</th>\n",
       "      <th>Team2SPG</th>\n",
       "      <th>Team2BPG</th>\n",
       "      <th>Team2PFPG</th>\n",
       "      <th>Team2TOPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.843750</td>\n",
       "      <td>32.656250</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>7.656250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.093750</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66.806452</td>\n",
       "      <td>39.225806</td>\n",
       "      <td>12.354839</td>\n",
       "      <td>7.645161</td>\n",
       "      <td>3.064516</td>\n",
       "      <td>20.870968</td>\n",
       "      <td>16.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.206897</td>\n",
       "      <td>35.551724</td>\n",
       "      <td>15.275862</td>\n",
       "      <td>7.517241</td>\n",
       "      <td>...</td>\n",
       "      <td>14.793103</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.965517</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>12.206897</td>\n",
       "      <td>6.344828</td>\n",
       "      <td>5.034483</td>\n",
       "      <td>13.827586</td>\n",
       "      <td>13.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.531250</td>\n",
       "      <td>35.187500</td>\n",
       "      <td>17.812500</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>13.312500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.724138</td>\n",
       "      <td>35.172414</td>\n",
       "      <td>15.655172</td>\n",
       "      <td>5.931034</td>\n",
       "      <td>2.103448</td>\n",
       "      <td>15.379310</td>\n",
       "      <td>12.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.515152</td>\n",
       "      <td>32.909091</td>\n",
       "      <td>15.363636</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>13.393939</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65.774194</td>\n",
       "      <td>38.806452</td>\n",
       "      <td>12.354839</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>3.806452</td>\n",
       "      <td>17.870968</td>\n",
       "      <td>17.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>74.103448</td>\n",
       "      <td>33.931034</td>\n",
       "      <td>14.172414</td>\n",
       "      <td>8.482759</td>\n",
       "      <td>...</td>\n",
       "      <td>13.241379</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.272727</td>\n",
       "      <td>35.242424</td>\n",
       "      <td>17.030303</td>\n",
       "      <td>8.030303</td>\n",
       "      <td>4.939394</td>\n",
       "      <td>16.121212</td>\n",
       "      <td>14.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.882353</td>\n",
       "      <td>33.676471</td>\n",
       "      <td>14.411765</td>\n",
       "      <td>9.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>12.147059</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76.727273</td>\n",
       "      <td>38.424242</td>\n",
       "      <td>13.848485</td>\n",
       "      <td>6.030303</td>\n",
       "      <td>5.060606</td>\n",
       "      <td>16.303030</td>\n",
       "      <td>12.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.823529</td>\n",
       "      <td>40.911765</td>\n",
       "      <td>18.941176</td>\n",
       "      <td>5.235294</td>\n",
       "      <td>...</td>\n",
       "      <td>12.852941</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>41.764706</td>\n",
       "      <td>15.911765</td>\n",
       "      <td>9.470588</td>\n",
       "      <td>6.823529</td>\n",
       "      <td>15.852941</td>\n",
       "      <td>13.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.823529</td>\n",
       "      <td>40.911765</td>\n",
       "      <td>18.941176</td>\n",
       "      <td>5.235294</td>\n",
       "      <td>...</td>\n",
       "      <td>12.852941</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.093750</td>\n",
       "      <td>34.281250</td>\n",
       "      <td>14.031250</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>4.906250</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>12.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.882353</td>\n",
       "      <td>33.676471</td>\n",
       "      <td>14.411765</td>\n",
       "      <td>9.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>12.147059</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.843750</td>\n",
       "      <td>34.625000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>14.656250</td>\n",
       "      <td>9.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.843750</td>\n",
       "      <td>34.625000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.093750</td>\n",
       "      <td>34.281250</td>\n",
       "      <td>14.031250</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>4.906250</td>\n",
       "      <td>17.781250</td>\n",
       "      <td>12.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Team1ID  Team2ID  Winner  Team1W  Team1L   Team1PPG   Team1RPG  \\\n",
       "0    2006.0   1284.0   1214.0     1.0    18.0    14.0  64.843750  32.656250   \n",
       "1    2006.0   1266.0   1104.0     2.0    19.0    10.0  74.206897  35.551724   \n",
       "2    2006.0   1130.0   1334.0     1.0    25.0     7.0  74.531250  35.187500   \n",
       "3    2006.0   1181.0   1380.0     1.0    30.0     3.0  82.515152  32.909091   \n",
       "4    2006.0   1375.0   1196.0     2.0    23.0     6.0  74.103448  33.931034   \n",
       "..      ...      ...      ...     ...     ...     ...        ...        ...   \n",
       "918  2019.0   1120.0   1246.0     1.0    25.0     9.0  78.882353  33.676471   \n",
       "919  2019.0   1277.0   1181.0     1.0    28.0     6.0  78.823529  40.911765   \n",
       "920  2019.0   1277.0   1403.0     2.0    28.0     6.0  78.823529  40.911765   \n",
       "921  2019.0   1120.0   1438.0     2.0    25.0     9.0  78.882353  33.676471   \n",
       "922  2019.0   1438.0   1403.0     1.0    29.0     3.0  71.843750  34.625000   \n",
       "\n",
       "      Team1APG  Team1SPG  ...  Team1TOPG  Team2W  Team2L   Team2PPG  \\\n",
       "0    14.656250  7.656250  ...  15.093750    16.0    15.0  66.806452   \n",
       "1    15.275862  7.517241  ...  14.793103    17.0    12.0  69.965517   \n",
       "2    17.812500  5.937500  ...  13.312500    22.0     7.0  73.724138   \n",
       "3    15.363636  9.545455  ...  13.393939    19.0    12.0  65.774194   \n",
       "4    14.172414  8.482759  ...  13.241379    27.0     6.0  79.272727   \n",
       "..         ...       ...  ...        ...     ...     ...        ...   \n",
       "918  14.411765  9.294118  ...  12.147059    27.0     6.0  76.727273   \n",
       "919  18.941176  5.235294  ...  12.852941    29.0     5.0  83.500000   \n",
       "920  18.941176  5.235294  ...  12.852941    26.0     6.0  73.093750   \n",
       "921  14.411765  9.294118  ...  12.147059    29.0     3.0  71.843750   \n",
       "922  14.500000  5.625000  ...   9.031250    26.0     6.0  73.093750   \n",
       "\n",
       "      Team2RPG   Team2APG  Team2SPG  Team2BPG  Team2PFPG  Team2TOPG  \n",
       "0    39.225806  12.354839  7.645161  3.064516  20.870968  16.225806  \n",
       "1    37.000000  12.206897  6.344828  5.034483  13.827586  13.517241  \n",
       "2    35.172414  15.655172  5.931034  2.103448  15.379310  12.551724  \n",
       "3    38.806452  12.354839  7.580645  3.806452  17.870968  17.580645  \n",
       "4    35.242424  17.030303  8.030303  4.939394  16.121212  14.878788  \n",
       "..         ...        ...       ...       ...        ...        ...  \n",
       "918  38.424242  13.848485  6.030303  5.060606  16.303030  12.636364  \n",
       "919  41.764706  15.911765  9.470588  6.823529  15.852941  13.117647  \n",
       "920  34.281250  14.031250  7.375000  4.906250  17.781250  12.375000  \n",
       "921  34.625000  14.500000  5.625000  3.812500  14.656250   9.031250  \n",
       "922  34.281250  14.031250  7.375000  4.906250  17.781250  12.375000  \n",
       "\n",
       "[923 rows x 22 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed()\n",
    "\n",
    "# make a new empty dataframe to hold all of the data\n",
    "\n",
    "# note: \"Winner\" column will always be '1' because the winning team is always listed first;\n",
    "# it's included just for a classification metric for the machine learning\n",
    "train_cols = [\"Season\", \"Team1ID\", \"Team2ID\", \"Winner\", \"Team1W\", \"Team1L\", \"Team1PPG\", \"Team1RPG\", \"Team1APG\", \"Team1SPG\", \\\n",
    "              \"Team1BPG\", \"Team1PFPG\", \"Team1TOPG\", \"Team2W\", \"Team2L\", \"Team2PPG\", \"Team2RPG\", \"Team2APG\", \"Team2SPG\",\\\n",
    "              \"Team2BPG\", \"Team2PFPG\", \"Team2TOPG\"]\n",
    "\n",
    "train_DF = pd.DataFrame(columns=train_cols)\n",
    "\n",
    "# we just need three columns from our tourney_df\n",
    "trim_tourney_df = tourney_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "trim_tourney_df\n",
    "\n",
    "for year in years:\n",
    "    avg_year_df = team_avgs[team_avgs['Season'] == year]\n",
    "    tourney_year_df = trim_tourney_df[trim_tourney_df['Season'] == year].apply(pd.to_numeric)\n",
    "    \n",
    "    for index, row in tourney_year_df.iterrows():\n",
    "        # make a list that we can insert into the new dataframe\n",
    "        #first 4 values (last value is the \"Winner\" classification which is randomly chosen)\n",
    "        \n",
    "        #randomly choose which slot the winning team goes into\n",
    "        winning_team = random.randint(1,2)\n",
    "        losing_team = 2 if winning_team == 1 else 1\n",
    "        \n",
    "        #properly put winning team into correct row\n",
    "        team_id = [\"\", \"WTeamID\", \"LTeamID\"]\n",
    "        temp_list = [year, row[team_id[winning_team]], row[team_id[losing_team]], winning_team]\n",
    "        team1_row = avg_year_df[avg_year_df[\"TeamID\"] == temp_list[1]][cols[2:]].values.tolist()\n",
    "        team2_row = avg_year_df[avg_year_df[\"TeamID\"] == temp_list[2]][cols[2:]].values.tolist()\n",
    "        temp_list.extend(team1_row[0])\n",
    "        temp_list.extend(team2_row[0])\n",
    "        \n",
    "        # add that list to our DF\n",
    "        temp_series = pd.Series(temp_list, index=train_cols)\n",
    "        train_DF = train_DF.append(temp_series, ignore_index=True)\n",
    "\n",
    "test_data = train_DF[train_DF['Season'] == 2019]\n",
    "test_labels = test_data['Winner']\n",
    "test_data = test_data.drop(columns=['Winner'])\n",
    "\n",
    "train_data = train_DF[train_DF['Season'] != 2019]\n",
    "train_labels = train_data['Winner']\n",
    "train_data = train_data.drop(columns=['Winner'])\n",
    "\n",
    "\n",
    "train_DF\n",
    "#train_data\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>PFPG</th>\n",
       "      <th>TOPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.827586</td>\n",
       "      <td>41.482759</td>\n",
       "      <td>18.206897</td>\n",
       "      <td>6.655172</td>\n",
       "      <td>5.862069</td>\n",
       "      <td>15.413793</td>\n",
       "      <td>11.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.558824</td>\n",
       "      <td>41.352941</td>\n",
       "      <td>19.911765</td>\n",
       "      <td>6.705882</td>\n",
       "      <td>5.705882</td>\n",
       "      <td>16.470588</td>\n",
       "      <td>13.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.588235</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>15.441176</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>4.147059</td>\n",
       "      <td>15.911765</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>15.843750</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>3.406250</td>\n",
       "      <td>15.843750</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.718750</td>\n",
       "      <td>39.937500</td>\n",
       "      <td>14.593750</td>\n",
       "      <td>8.781250</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>18.562500</td>\n",
       "      <td>12.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>38.766667</td>\n",
       "      <td>12.633333</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>75.470588</td>\n",
       "      <td>34.882353</td>\n",
       "      <td>13.941176</td>\n",
       "      <td>5.764706</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>14.382353</td>\n",
       "      <td>12.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.903226</td>\n",
       "      <td>41.548387</td>\n",
       "      <td>14.096774</td>\n",
       "      <td>6.322581</td>\n",
       "      <td>4.451613</td>\n",
       "      <td>16.806452</td>\n",
       "      <td>13.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.233333</td>\n",
       "      <td>39.533333</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>14.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>76.911765</td>\n",
       "      <td>38.352941</td>\n",
       "      <td>15.029412</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.735294</td>\n",
       "      <td>20.264706</td>\n",
       "      <td>14.205882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  TeamID  Wins  Losses        PPG        RPG        APG       SPG  \\\n",
       "0   2022.0  1211.0  26.0     3.0  87.827586  41.482759  18.206897  6.655172   \n",
       "1   2022.0  1112.0  31.0     3.0  84.558824  41.352941  19.911765  6.705882   \n",
       "2   2022.0  1242.0  28.0     6.0  78.588235  37.352941  15.441176  6.411765   \n",
       "3   2022.0  1124.0  26.0     6.0  76.500000  37.125000  15.843750  8.812500   \n",
       "4   2022.0  1120.0  27.0     5.0  78.718750  39.937500  14.593750  8.781250   \n",
       "..     ...     ...   ...     ...        ...        ...        ...       ...   \n",
       "63  2022.0  1313.0  24.0     6.0  75.100000  38.766667  12.633333  6.700000   \n",
       "64  2022.0  1460.0  21.0    13.0  75.470588  34.882353  13.941176  5.764706   \n",
       "65  2022.0  1136.0  22.0     9.0  77.903226  41.548387  14.096774  6.322581   \n",
       "66  2022.0  1411.0  18.0    12.0  69.233333  39.533333  10.833333  5.566667   \n",
       "67  2022.0  1394.0  23.0    11.0  76.911765  38.352941  15.029412  8.500000   \n",
       "\n",
       "         BPG       PFPG       TOPG  \n",
       "0   5.862069  15.413793  11.758621  \n",
       "1   5.705882  16.470588  13.176471  \n",
       "2   4.147059  15.911765  12.500000  \n",
       "3   3.406250  15.843750  12.500000  \n",
       "4   7.937500  18.562500  12.093750  \n",
       "..       ...        ...        ...  \n",
       "63  3.666667  17.666667  14.000000  \n",
       "64  2.941176  14.382353  12.294118  \n",
       "65  4.451613  16.806452  13.903226  \n",
       "66  5.000000  17.800000  14.933333  \n",
       "67  1.735294  20.264706  14.205882  \n",
       "\n",
       "[68 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_2022_df = pd.read_csv(\"./2022RegularSeason.csv\",\n",
    "                    names=['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
    "                    #dtype={'Season': 'str', 'DayNum': 'str', 'WTeamID': 'str', 'WScore': 'int', 'LTeamID': 'str', 'LScore': 'int', 'WLoc': 'str', 'NumOT': 'str', 'WFGM': 'int', 'WFGA': 'int', 'WFGM3': 'int', 'WFGA3': 'int', 'WFTM': 'int', 'WFTA': 'int', 'WOR': 'int', 'WDR': 'int', 'WAst': 'int', 'WTO': 'int', 'WStl': 'int', 'WBlk': 'int', 'WPF': 'int', 'LFGM': 'int', 'LFGA': 'int', 'LFGM3': 'int', 'LFGA3': 'int', 'LFTM': 'int', 'LFTA': 'int', 'LOR': 'int', 'LDR': 'int', 'LAst': 'int', 'LTO': 'int', 'LStl': 'int', 'LBlk': 'int', 'LPF': 'int'},\n",
    "                    encoding = \"ISO-8859-1\")\n",
    "reg_2022_df = reg_2022_df.drop(labels=0, axis=0)\n",
    "tourney_team_ids = [1211, 1112,1242,1124, 1120, 1246,1437, 1181, 1458, 1397,1345,1403,1417, 1228, 1344, 1116, 1163, 1222, 1388, 1234, 1104, 1261, 1400, 1161, 1425, 1293,1277, 1326, 1129, 1314, 1361,1371, 1166, 1395, 1266, 1272, 1362, 1274, 1260, 1172,1235, 1276,1461,1353,1231, 1439, 1323,1412,1350,1308,1151, 1355, 1436,1103, 1255,1463, 1159, 1286, 1174,1389,1240,1168,1209, 1313, 1460, 1136,1411, 1394]\n",
    "team_avgs_2022 = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in tourney_team_ids:\n",
    "    team_wins = reg_2022_df[reg_2022_df['WTeamID'] == str(key)]\n",
    "    team_losses = reg_2022_df[reg_2022_df['LTeamID'] == str(key)]\n",
    "    \n",
    "    team_win_df = team_wins[['Season', 'WTeamID', 'WScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].apply(pd.to_numeric)\n",
    "    team_loss_df = team_losses[['Season', 'LTeamID', 'LScore', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].apply(pd.to_numeric)\n",
    "\n",
    "    w_sum = team_win_df.sum(axis=0, numeric_only=True)\n",
    "\n",
    "    l_sum = {'Season': 0, 'LTeamID': 0, 'LScore': 0, 'LFGM': 0, 'LFGA': 0, 'LFGM3': 0, 'LFGA3': 0, 'LFTM': 0, 'LFTA': 0, 'LOR': 0, 'LDR': 0, 'LAst': 0, 'LTO': 0, 'LStl': 0, 'LBlk': 0, 'LPF': 0}\n",
    "    if not team_losses.empty:\n",
    "        l_sum = team_loss_df.sum(axis=0, numeric_only=True)\n",
    "\n",
    "    tot_games = (len(team_win_df.index) + len(team_loss_df.index))\n",
    "    season_total = (int(w_sum['Season']) + int(l_sum['Season'])) / tot_games\n",
    "    id_total = (w_sum['WTeamID'] + l_sum['LTeamID']) / tot_games\n",
    "    score_total = (w_sum['WScore'] + l_sum['LScore']) / tot_games\n",
    "    rebs_total = (w_sum['WOR'] + l_sum['LOR'] + w_sum['WDR'] + l_sum['LDR']) / tot_games\n",
    "    ast_total = (w_sum['WAst'] + l_sum['LAst']) / tot_games\n",
    "    stl_total = (w_sum['WStl'] + l_sum['LStl']) / tot_games\n",
    "    blk_total = (w_sum['WBlk'] + l_sum['LBlk']) / tot_games\n",
    "    pf_total = (w_sum['WPF'] + l_sum['LPF']) / tot_games\n",
    "    to_total = (w_sum['WTO'] + l_sum['LTO']) / tot_games\n",
    "       \n",
    "    team_avgs_2022.loc[len(team_avgs_2022.index)] = [season_total, id_total, len(team_win_df.index), len(team_loss_df.index), score_total, rebs_total, ast_total, stl_total, blk_total, pf_total, to_total]\n",
    "team_avgs_2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = {'Team1ID': [1211,1129,1163,1116,1104,1403,1277,1181,1124,1314,1388,1417,1400,1345     1211,1308,1323,1277,1124,], 'Team2ID': [1209,1272,1308,1436,1323,1268,1172,1168,1313,1266,1231,1103,1439,1463,       1272,1116,1403, 1181]}\n",
    "#temp_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: 0.22388059701492538\n",
      "Trial 2: 0.746268656716418\n",
      "Trial 3: 0.835820895522388\n",
      "Trial 4: 0.07462686567164178\n",
      "Trial 5: 1.0\n",
      "Trial 6: 0.26865671641791045\n",
      "Trial 7: 0.8507462686567164\n",
      "Trial 8: 0.1791044776119403\n",
      "Trial 9: 0.014925373134328358\n",
      "Trial 10: 0.0\n",
      "Trial 11: 0.5223880597014925\n",
      "Trial 12: 0.16417910447761194\n",
      "Trial 13: 0.0\n",
      "Trial 14: 0.26865671641791045\n",
      "Trial 15: 0.9402985074626866\n",
      "Trial 16: 0.6268656716417911\n",
      "Trial 17: 0.6865671641791045\n",
      "Trial 18: 0.19402985074626866\n",
      "Trial 19: 0.11940298507462686\n",
      "Trial 20: 0.2537313432835821\n",
      "Trial 21: 0.1044776119402985\n",
      "Trial 22: 0.47761194029850745\n",
      "Trial 23: 0.47761194029850745\n",
      "Trial 24: 0.9850746268656716\n",
      "Trial 25: 0.1791044776119403\n",
      "Trial 26: 1.0\n",
      "Trial 27: 0.1791044776119403\n",
      "Trial 28: 1.0\n",
      "Trial 29: 0.22388059701492538\n",
      "Trial 30: 0.5373134328358209\n",
      "Trial 31: 0.7761194029850746\n",
      "Trial 32: 1.0\n",
      "Trial 33: 0.6567164179104478\n",
      "Trial 34: 0.0\n",
      "Trial 35: 0.31343283582089554\n",
      "Trial 36: 0.835820895522388\n",
      "Trial 37: 0.9402985074626866\n",
      "Trial 38: 0.8805970149253731\n",
      "Trial 39: 0.8208955223880597\n",
      "Trial 40: 0.0\n",
      "Trial 41: 0.04477611940298507\n",
      "Trial 42: 0.3582089552238806\n",
      "Trial 43: 0.9253731343283582\n",
      "Trial 44: 0.014925373134328358\n",
      "Trial 45: 0.11940298507462686\n",
      "Trial 46: 0.8805970149253731\n",
      "Trial 47: 0.6417910447761194\n",
      "Trial 48: 1.0\n",
      "Trial 49: 0.8955223880597015\n",
      "Trial 50: 1.0\n",
      "Trial 51: 0.13432835820895522\n",
      "Trial 52: 0.0\n",
      "Trial 53: 0.6567164179104478\n",
      "Trial 54: 0.3582089552238806\n",
      "Trial 55: 0.9552238805970149\n",
      "Trial 56: 0.417910447761194\n",
      "Trial 57: 0.9850746268656716\n",
      "Trial 58: 0.014925373134328358\n",
      "Trial 59: 0.8656716417910447\n",
      "Trial 60: 0.0\n",
      "Trial 61: 0.08955223880597014\n",
      "Trial 62: 0.0\n",
      "Trial 63: 0.7910447761194029\n",
      "Trial 64: 1.0\n",
      "Trial 65: 0.9402985074626866\n",
      "Trial 66: 0.0\n",
      "Trial 67: 0.7910447761194029\n",
      "Trial 68: 0.11940298507462686\n",
      "Trial 69: 0.9701492537313433\n",
      "Trial 70: 0.0\n",
      "Trial 71: 0.34328358208955223\n",
      "Trial 72: 0.04477611940298507\n",
      "Trial 73: 0.3283582089552239\n",
      "Trial 74: 1.0\n",
      "Trial 75: 0.7761194029850746\n",
      "Trial 76: 0.6119402985074627\n",
      "Trial 77: 0.11940298507462686\n",
      "Trial 78: 0.07462686567164178\n",
      "Trial 79: 0.08955223880597014\n",
      "Trial 80: 0.3880597014925373\n",
      "Trial 81: 0.8656716417910447\n",
      "Trial 82: 1.0\n",
      "Trial 83: 0.6865671641791045\n",
      "Trial 84: 0.0\n",
      "Trial 85: 0.6119402985074627\n",
      "Trial 86: 0.47761194029850745\n",
      "Trial 87: 0.208955223880597\n",
      "Trial 88: 0.3880597014925373\n",
      "Trial 89: 0.4925373134328358\n",
      "Trial 90: 0.0\n",
      "Trial 91: 0.4925373134328358\n",
      "Trial 92: 0.8507462686567164\n",
      "Trial 93: 0.29850746268656714\n",
      "Trial 94: 0.014925373134328358\n",
      "Trial 95: 0.5522388059701493\n",
      "Trial 96: 0.0\n",
      "Trial 97: 1.0\n",
      "Trial 98: 0.2835820895522388\n",
      "Trial 99: 0.835820895522388\n",
      "Trial 100: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.8, 0.8, 1.2, 1. , 0.6, 1. , 0.6, 0.8, 0.2, 1. , 0.4, 0.2, 0.8,\n",
       "        0.8, 0.2, 0.8, 0.8, 1.4, 0.8, 2.8]),\n",
       " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    "predictions = model.predict(test_data)\n",
    "predictions\n",
    "\n",
    "# Correlation checking\n",
    "big_corr = []\n",
    "for m in range(1):\n",
    "    for n in range(10):\n",
    "        corr = []\n",
    "        for i in range(10):\n",
    "            model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    "            predictions1 = model.predict(test_data)\n",
    "            model = MLPClassifier(hidden_layer_sizes=200, max_iter=200).fit(train_data, train_labels)\n",
    "            predictions2 = model.predict(test_data)\n",
    "            sum1 = 0\n",
    "            for j in range(len(predictions1)):\n",
    "                sum1 = sum1 + 1 if predictions1[j] == predictions2[j] else sum1\n",
    "\n",
    "            sum1 /= len(predictions1)\n",
    "#            corr.append(sum1)\n",
    "            big_corr.append(sum1)\n",
    "            print(f\"Trial {m*100 + n*10 + i + 1}: {sum1}\")\n",
    "\n",
    "#        avg = sum(corr) / len(corr)\n",
    "#        print(avg)\n",
    "#        big_corr.append(avg)\n",
    "#        corr.clear()\n",
    "#    print(f\"Overall correlation average: {sum(big_corr)/len(big_corr)}\")\n",
    "#    big_corr.clear()\n",
    "\n",
    "\n",
    "plt.hist(big_corr, density=True, bins=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: 0.625\n",
      "Trial 1: 0.5625\n",
      "Trial 2: 0.75\n",
      "Trial 3: 0.6875\n",
      "Trial 4: 0.5\n",
      "Trial 5: 0.5625\n",
      "Trial 6: 0.8125\n",
      "Trial 7: 0.625\n",
      "Trial 8: 0.6875\n",
      "Trial 9: 0.6875\n",
      "Trial 10: 0.625\n",
      "Trial 11: 0.6875\n",
      "Trial 12: 0.6875\n",
      "Trial 13: 0.8125\n",
      "Trial 14: 0.75\n",
      "Trial 15: 0.9375\n",
      "Trial 16: 0.5625\n",
      "Trial 17: 0.6875\n",
      "Trial 18: 0.5625\n",
      "Trial 19: 0.75\n",
      "Average accuracy: 0.678125\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "train_df_year = train_DF[train_DF[\"Season\"] == 2010]\n",
    "X = train_df_year.drop(\"Season\", axis=1)\n",
    "X = X.drop([\"Winner\", \"Team1ID\", \"Team2ID\"], axis=1)\n",
    "y = train_df_year[\"Winner\"]\n",
    "y = y.astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X.values)\n",
    "\n",
    "X_proc = pd.DataFrame(scaled_X, index = X.index, columns = X.columns)\n",
    "\n",
    "accuracy_scores = []\n",
    "for i in range(20):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_proc, y, stratify=y)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "    # Model Fit\n",
    "    xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "    # Model Prediction\n",
    "    preds = xgb_cl.predict(X_test)\n",
    "\n",
    "    # Accuracy Score\n",
    "    accuracy_scores.append(accuracy_score(y_test, preds))\n",
    "    \n",
    "for i in range(len(accuracy_scores)):\n",
    "    print(f\"Trial {i}: {accuracy_scores[i]}\")\n",
    "print(f\"Average accuracy: {sum(accuracy_scores)/len(accuracy_scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
